<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Vision Transformer Doc</title>
<link rel="icon" href="LLM Vision Transformers a87c07d6e350428db36a8c325308fa43\favs.png" >
<style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="a87c07d6-e350-428d-b36a-8c325308fa43" class="page sans"><header><img class="page-cover-image" src="https://www.notion.so/images/page-cover/met_fitz_henry_lane.jpg" style="object-position:center 46.85%"/><div class="page-header-icon page-header-icon-with-cover"><span class="icon">ðŸ‘¾</span></div><h1 class="page-title">LLM Vision Transformers</h1><p class="page-description"></p></header><div class="page-body"><hr id="e2356681-4bd5-46be-8d79-da75f8f26c24"/><h1 id="80c19bf2-37f7-4cd1-97ab-3585e00e0335" class="">import torch</h1><hr id="fba0e738-ace0-4329-b4d8-900144835b82"/><p id="daeef218-5c91-4fa6-aeee-029ea7e8ab44" class="">Pytorch is a open source machine learning library for tensor computation for building and training neural networks</p><hr id="54ee5b2b-fc8e-4865-ac33-e72a55419a8e"/><h1 id="626e0fa8-b0b6-402c-984d-9b67b7871616" class="">Torchvision</h1><hr id="ba9f9fc7-eec4-4c20-a561-bd3bd88c32a6"/><p id="4db9ef3b-8156-47ae-a477-d16b8e1a173d" class="">itâ€™s a package which is a part of the Pytorch ecosystem which provides utility functions, datasets, pre-trained models  for common tasks like data loading image transformations, model architecture access Etc.</p><hr id="bb522ff7-de68-459c-bb40-4a4f92aed934"/><h1 id="d70499c7-c50c-44a2-a8c1-48909247d7f7" class="">from torch import <span style="border-bottom:0.05em solid"><strong>nn</strong></span></h1><hr id="ee3af4d6-fed7-457d-80a1-a737c7e4aa2b"/><p id="5983bc41-0a7a-440b-90d9-ce5f6fa8adb5" class="">provides an interface for implementing neural networks, it contains pre-defined layers, loss functions, utility functions used for neural network construction</p><hr id="cc67c1de-5592-4bed-a890-0e9a6dbd8124"/><h1 id="58846c4a-472e-46a1-8fbe-2f90efb760b1" class="">nn </h1><hr id="92d63eda-499f-488f-a3db-fcef01bc7f90"/><p id="0a236016-2567-403f-9de6-4e28dc9a86e0" class="">nn module has wide range of pre-defined <strong><mark class="highlight-orange">neural network architectures</mark></strong><mark class="highlight-orange"> </mark>they have Layers like C<strong>onnected Layers</strong> ( Linear )  where each input neuron is connected to each output neuron by a weighted connection. It performs a linear transformation on the input data, </p><p id="81a9f871-7dc4-4655-8a26-c27d318d7933" class=""><strong>Convolutional Layers</strong> ( Conv2d , ConvTranspose2d ) This creates a 2D convolutional layer, which applies a 2D convolution operation to the input tensor. It&#x27;s commonly used for extracting spatial features from images. the transpose is called deconvolution layer, itâ€™s used in unsampling or generating high resolution images from low resolution representations</p><p id="6ce3dcaa-a131-4d57-aabf-4553fc6777a3" class=""><strong>Recurrent Layers</strong> ( LSTM , GRU ) This creates a Long Short-Term Memory (LSTM) layer, a type of recurrent neural network (RNN) architecture designed to capture long-term dependencies in sequential data. GRU is like LSTM but not much powerful</p><p id="1c69405e-eac4-4892-93ce-6994db56bb5f" class=""><mark class="highlight-orange">Activation functions</mark></p><p id="9b2c71a1-c9f4-4584-a68c-e94b7b471e9f" class=""><strong>ReLU</strong>  activation function, which introduces non-linearity by replacing negative values in the input tensor with zero.</p><p id="dcd4178d-7ccf-4b94-910f-099297e84829" class=""><strong>Sigmoid</strong>  This creates a sigmoid activation function, which squashes input values to the range [0, 1], often used for binary classification tasks.</p><p id="15a912af-14c0-4c02-9d47-10ef30760282" class=""><strong>Tanh</strong>  This creates a hyperbolic tangent (tanh) activation function, which squashes input values to the range [-1, 1], often used for capturing non-linear relationships in data.</p><hr id="8e133597-50ea-4e48-a33d-c576d8711af1"/><h1 id="c04abf31-9dc1-4ce1-b5ac-be299cf828b6" class="">torchvision.transforms  â‡’ for image transformations</h1><hr id="fb9acf7e-8482-459b-b059-2dff9ba21f67"/><p id="fe9cf2b1-508b-4b67-9a46-6306e3e7ca92" class="">Used for Data preprocessing like converting images to tensors ( array of numbers ) , Data Augmentation like flipping, rotating, changing brightness , Etc.</p><hr id="2ba59c57-05b5-466b-897a-d3a887c34e3b"/><h1 id="e11366a6-a6b7-4590-99a8-66f9b6be74bd" class="">torch.cuda.is_available ( )</h1><hr id="9eb9a7e2-3231-42f5-a6e1-075cead4b935"/><p id="f79610a2-c253-4b25-a73c-159feee0a2cd" class="">It checks if CUDA (computer unified device architecture) is available on the system or not</p><p id="64396342-6b01-4468-b495-5c05253164ee" class="">CUDA is NVDIAâ€™s parallel computing platform, if itâ€™s available, then u can use NVDIA GPU for accelerated computing </p><hr id="30c9c4f8-9a3a-4607-8642-00f9e51ee10d"/><h1 id="d0ad2139-98ca-4a7b-8912-a11a70e17375" class="">create DataLoaders  </h1><hr id="ca1a33ae-0978-4719-8648-03974b1c940b"/><p id="36ed3beb-13ad-4596-9d32-a7d249cf1e60" class=""><mark class="highlight-blue"><strong><code>os.cpu_count()</code></strong></mark><mark class="highlight-orange"> </mark><mark class="highlight-default">is used to retrieve the number of CPU cores regardless of CUDA availability coz, data loading operations are performed on CPU</mark></p><p id="76eb646d-eff2-4e66-9dfa-faf561934c1f" class="">from torch.utils.data import DataLoader  â‡’ which helps in creating data loaders for iterating over datasets during training or inference.</p><p id="50a21f18-d443-41b5-be85-cb2c6d51c9d7" class=""><br/>â€¢ <br/><mark class="highlight-blue"><code><strong>transform</strong></code></mark> is a parameter of the <mark class="highlight-blue"><code><strong>create_dataloaders</strong></code></mark> function. It&#x27;s used to specify a sequence of transformations to be applied to input images before they are fed into the neural network for training or testing.</p><p id="5ee2f969-d61c-4d0b-bd72-e99481788389" class=""><br/>â€¢ <br/><mark class="highlight-blue"><code><strong>transforms.Compose</strong></code></mark> is a class provided by PyTorch&#x27;s <mark class="highlight-teal"><code><strong>torchvision.transforms</strong></code></mark> module. It allows you to combine multiple transformations into a single transformation pipeline.</p><p id="773ddb76-dfae-47d5-be82-f623215d480d" class=""><br/>â€¢ <br/><code><strong>batch_size</strong></code> is another parameter of the <mark class="highlight-blue"><code><strong>create_dataloaders</strong></code></mark> function. It specifies the number of samples (images in this case) that will be loaded into the neural network at once during training or testing.</p><hr id="824e10c4-a25c-4bfa-96d6-59bf6d5000ce"/><h1 id="32462e57-bd23-4206-860c-d37da578ba27" class="">ImageFolder</h1><hr id="e2b4614f-d444-4f13-a314-889435b67950"/><p id="8fb5bfa9-7d9d-4ad3-9056-22461ed16e01" class=""><mark class="highlight-blue"><strong><code>train_data = datasets.ImageFolder(train_dir,transform=transform)</code></strong></mark><strong> </strong>It assumes that the images are organized in folders where each folder represents a class. the transformations are not applied yet, they are stored in the train_data </p><hr id="d759b7e6-047f-4d1f-9439-894a45d4b2a6"/><h1 id="5251674e-dc8e-4f15-ab36-f2a4ba6af930" class="">DataLoader load </h1><p id="e66947be-c4fd-4bb5-b941-f22c770e0506" class=""><mark class="highlight-teal"><strong><code>The transformations are applied dynamically during data loading</code></strong></mark> </p><hr id="5e2acc98-7ed3-4252-b0f2-ac3350269eea"/><p id="299bd6c5-6f3d-417c-b8ae-8e8364d9544d" class=""><br/>â€¢ <br/><mark class="highlight-blue"><code><strong>DataLoader</strong></code></mark> is a class provided by PyTorch&#x27;s <code><strong>torch.utils.data</strong></code> module. It&#x27;s used to create an iterable object that loads data from a dataset in batches.</p><p id="ad9e6519-007a-44e7-a12c-d682971f69b3" class=""><br/>â€¢ <br/><code><strong>shuffle=True</strong></code>: This parameter specifies whether to shuffle the dataset before forming batches. Shuffling the data helps in randomizing the order of samples, preventing the model from learning the sequence of data and making the training more robust.</p><p id="a82495d3-fb7d-4d34-965f-d57493ab9ffb" class="">
</p><p id="ae9731e9-f29b-4086-a8d1-5aa3582cbc07" class="">When <mark class="highlight-blue"><code><strong>pin_memory=True</strong></code></mark> is set in the <mark class="highlight-blue"><code><strong>DataLoader</strong></code></mark>, it means that PyTorch will use a special type of memory called pinned memory for transferring data between the CPU and GPU during training. Pinned memory is faster to transfer than regular memory because it&#x27;s locked in place and doesn&#x27;t get moved around by the operating system.<br/><br/></p><p id="45b0c9ea-1a08-4ab8-a0e0-adc09e3bf6ab" class="">setting <mark class="highlight-blue"><code><strong>pin_memory=True</strong></code></mark> is like using an express lane for data transfer between the CPU and GPU, helping your training process run smoother.</p><hr id="dd961656-4012-4be4-8a62-6e1ede5dae52"/><h1 id="014682df-37b8-47d3-aec6-0b530ec82b92" class="">Manual transforms</h1><hr id="f20664df-75cc-4265-8b76-59faa99b50d5"/><ol type="1" id="15cb6cde-1557-44b3-b5a0-dda24b740def" class="numbered-list" start="1"><li><mark class="highlight-blue"><code><strong>transforms.Resize((IMG_SIZE, IMG_SIZE))</strong></code></mark>:<ul id="553c341f-f64c-48a7-a420-954d2514176b" class="bulleted-list"><li style="list-style-type:disc">This transformation resizes each image in the dataset to a square size specified by <code><strong>IMG_SIZE</strong></code> (224x224 pixels in this case).</li></ul><ul id="cc18f4a3-06a4-4af1-ad4a-1e949085d298" class="bulleted-list"><li style="list-style-type:disc">Resizing the images ensures that they all have the same dimensions, which is often necessary for feeding them into a neural network, as most models expect images of a consistent size.</li></ul></li></ol><ol type="1" id="2a6dbb8d-a351-4cb4-8212-eaf245801699" class="numbered-list" start="2"><li><mark class="highlight-blue"><code><strong>transforms.ToTensor()</strong></code></mark>:<ul id="670befef-fed5-4c0e-a2a8-62d400f290e1" class="bulleted-list"><li style="list-style-type:disc">This transformation converts the resized images from PIL (Python Imaging Library) format to PyTorch tensors.</li></ul><ul id="8bd9c54a-17fe-4459-9ad9-d427751fbd1e" class="bulleted-list"><li style="list-style-type:disc">PyTorch tensors are multi-dimensional arrays that can be efficiently processed by neural networks.</li></ul><ul id="b7c228e6-cf16-4b82-8c5d-013dd8079056" class="bulleted-list"><li style="list-style-type:disc">Converting images to tensors is a fundamental step in preprocessing image data for deep learning tasks.</li></ul><hr id="89ab288a-f7fd-4c4a-96d8-d85f4e7df63e"/><h1 id="2f50e439-90ec-42d6-80ca-2ff2d5610059" class="">Output for manual transforms</h1><hr id="7b8bb9f9-32e7-4302-8f3c-3ce2684a8675"/><ol type="1" id="3812e18c-afb3-4534-a11f-d5934439011a" class="numbered-list" start="1"><li><strong>Anti-aliasing (antialias=True)</strong>:<ul id="ac8648db-917d-4dda-90e9-2c5b0e077800" class="bulleted-list"><li style="list-style-type:disc">Anti-aliasing is a technique used to reduce jagged edges that can occur when resizing images. It works by blending neighboring pixel values to create smoother transitions between colors.</li></ul><ul id="70fb87e8-ad60-45c8-ab8d-9a2dae91c311" class="bulleted-list"><li style="list-style-type:disc">When <mark class="highlight-blue"><code><strong>antialias=True</strong></code></mark>, it means that anti-aliasing is enabled during resizing, helping to produce higher-quality, more visually appealing images with smoother edges.</li></ul><figure id="92abdbec-33d5-485a-813b-84cffe485343" class="image"><a href="LLM%20Vision%20Transformers%20a87c07d6e350428db36a8c325308fa43/anti-aliasing.jpg"><img style="width:554px" src="LLM%20Vision%20Transformers%20a87c07d6e350428db36a8c325308fa43/anti-aliasing.jpg"/></a></figure></li></ol><ol type="1" id="a6a7987e-c666-405c-ba74-6477957b50ba" class="numbered-list" start="2"><li><strong>Maximum Size Constraint (max_size=None)</strong>:<ul id="b2a8da64-1a12-48e5-936a-03f5bcff4dbe" class="bulleted-list"><li style="list-style-type:disc">This parameter controls whether there&#x27;s a limit on how large the images can be resized. When <mark class="highlight-blue"><code><strong>max_size=None</strong></code></mark>, it means there&#x27;s no maximum size constraint imposed during resizing.</li></ul><ul id="9a8a9664-6f8f-4859-a78e-d07f83020dc2" class="bulleted-list"><li style="list-style-type:disc">Essentially, it allows the images to be resized to any size without restrictions based on a maximum dimension.</li></ul></li></ol><ol type="1" id="542b6c8a-f619-4266-b598-7ce61f3c582d" class="numbered-list" start="3"><li><strong>Interpolation (bilinear)</strong>:<ul id="c871f144-2473-4c25-8350-1957482920a8" class="bulleted-list"><li style="list-style-type:disc">Think of interpolation as a method for estimating values between known data points. In the context of resizing images, bilinear interpolation calculates new pixel values by averaging the values of nearby pixels. It&#x27;s like blending colors together to create a smooth transition between them.</li></ul><ul id="c71ecaa3-95e7-4a2c-aa06-370ff5406e9d" class="bulleted-list"><li style="list-style-type:disc">Itâ€™s a process of determining the unknown values that lie in between the known data points.</li></ul><ul id="375edf02-7744-4c47-8e25-9a16dc880e5e" class="bulleted-list"><li style="list-style-type:disc">Bilinear interpolation is commonly used because it&#x27;s simple and efficient. It creates smooth, visually pleasing results when resizing images.</li></ul><hr id="614fc1e0-78f9-4be7-b8c4-3e78de96f01a"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="7e52315c-56e2-409c-a7f8-f077b2b9cd89" class="code"><code class="language-Python">1 image_batch, label_batch = next(iter(train_dataloader))
2 image, label = image_batch[0], label_batch[0] 
3 print(image.shape, label)  </code></pre><hr id="41f87667-3ab2-44da-8386-7c8c13c0bf0f"/><p id="f8809e7b-b0a1-49ce-b579-de04e004f999" class="">the first line fetches a batch of images from the train_dataloader </p><p id="4bbd70dd-b341-40d2-8bae-cb9491c5bd25" class="">the second like takes the first image from the batch of the images</p><p id="3b37183e-daee-49e8-9eed-dec8d1c0662d" class="">the third line prints the image shape and label, The shape typically looks like </p><p id="9d11a0b8-3e2d-444f-af8c-517c05344ab7" class=""><code><strong>(channels, height, width)</strong></code>, where <code><strong>channels</strong></code> represents the color channels (e.g., 3 for RGB images).</p><hr id="0f851177-ea67-4c36-8b9d-5b3edae663bf"/><p id="c5bfcdb8-062f-482e-9da4-101483f5b1f2" class=""><mark class="highlight-blue"><code><strong>plt.imshow(image.permute(1, 2, 0))</strong></code></mark><mark class="highlight-blue">:</mark></p><ul id="f9f4f603-8b91-4480-bd5c-7df7fde7a495" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>plt.imshow()</strong></code></mark> is a function from the Matplotlib library used to display images.</li></ul><ul id="75f39620-8f36-4ff7-baaf-5df05aaf8a6f" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>image.permute(1, 2, 0)</strong></code></mark> rearranges the dimensions of the image tensor to match Matplotlib&#x27;s expected format of <code><strong>[height, width, channels]</strong></code>. The default tensor format is  <code><strong>(channels, height, width)</strong></code></li></ul><hr id="a9c9a52f-4fa1-4b20-978e-942eade9e8ca"/><h1 id="de618f4e-4873-41e9-bb8f-97feb8ca8325" class="">Patch Embedding</h1><hr id="f133bcb6-a051-4575-901a-bb63bc020449"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="7bca24e9-d820-4613-8cea-96a4d1dbccbc" class="code"><code class="language-Python">class PatchEmbedding(nn.Module):
    &quot;&quot;&quot;Turns a 2D input image into a 
    1D sequence learnable embedding vector.

    Args:
        in_channels (int): Number of color channels for the input images. Defaults to 3.
        patch_size (int): Size of patches to convert input image into. Defaults to 16.
        embedding_dim (int): Size of embedding to turn image into. Defaults to 768.
    &quot;&quot;&quot;
    # 2. Initialize the class with appropriate variables
    def __init__(self,
                 in_channels:int=1,
                 patch_size:int=16,
                 embedding_dim:int=768):
        super().__init__()

        # 3. Create a layer to turn an image into patches
        self.patcher = nn.Conv2d(in_channels=in_channels,
                                 out_channels=embedding_dim,
                                 kernel_size=patch_size,
                                 stride=patch_size,
                                 padding=0)

        # 4. Create a layer to flatten the patch feature maps into a single dimension
        self.flatten = nn.Flatten(start_dim=2, # only flatten the feature map dimensions into a single vector
                                  end_dim=3)

    # 5. Define the forward method
    def forward(self, x):
        # Create assertion to check that inputs are the correct shape
        image_resolution = x.shape[-1]
        assert image_resolution % patch_size == 0, f&quot;Input image size must be divisble by patch size, image shape: {image_resolution}, patch size: {patch_size}&quot;

        # Perform the forward pass
        x_patched = self.patcher(x)
        x_flattened = self.flatten(x_patched)

        # 6. Make sure the output shape has the right order
        return x_flattened.permute(0, 2, 1) # adjust so the embedding is on the final dimension [batch_size, P^2â€¢C, N] -&gt; [batch_size, N, P^2â€¢C]</code></pre></li></ol><p id="4c21c8a9-4462-40b3-a3f7-bdf8520b6944" class="">
</p></li></ol><p id="5221c7e3-0295-4eca-87d9-9c81583c85b7" class="">nn.Module : is a base class for the neural network modules, itâ€™s used to create custom layers in a model</p><p id="96e97179-17d2-4c62-b9b8-300defd6d4fa" class="">A patch embedding layer maps patches of pixels to vectors. Use this layer in vision transformer neural networks to encode information about patches in images.</p><p id="a81b30d2-62f6-46a9-84b1-9e1a2b313a1e" class=""><mark class="highlight-blue"><strong><code>in_channels</code></strong></mark> : Specifies the number of input channels (e.g., color channels) for the input images.Determines the depth of the input image tensor, allowing the patching layer (<code><strong>patcher</strong></code>) to correctly interpret the input data. 1 for grayscale images, 3 for RGB images</p><p id="885c77d5-d44d-42c0-8911-693849725660" class=""><mark class="highlight-blue"><strong><code>out_channels</code></strong></mark> (embedding_dim):<div class="indented"><p id="074b600f-a50f-4f55-a6db-97a1b2488516" class="">It Specifies the number of output channels, which is equivalent to the embedding dimension. It Determines the dimensionality of the output embedding vectors. 768 is default, but it can be adjusted based on the desired embedding dimension for the patch-based embeddings.</p></div></p><p id="53144058-6c29-49ae-b70e-22cf22cca846" class=""><strong><mark class="highlight-blue"><code>patch-size</code></mark></strong>  it defines the extend of each patch i.e the size of the divided patch</p><p id="4154e7cc-55c1-4c44-9d50-2ce93926037c" class=""><mark class="highlight-blue"><strong><code>embedding_dim</code></strong></mark>:  The embedding dimension refers to the size of the vector space in which entities, such as words, images, or other data points, are represented as dense vectors of real numbers. In image processing embeddings can represent features extracted from images <div class="indented"><ul id="3ae4e9de-a327-44ec-85ae-df9eee6eb4bf" class="bulleted-list"><li style="list-style-type:disc">Embedding vectors are designed to capture semantic meaning and relationships in the data.</li></ul><ul id="6443f85c-5292-4b79-adc2-84ed909d863d" class="bulleted-list"><li style="list-style-type:disc">Embeddings help reduce the dimensionality of the input data while preserving important relationships and structures.</li></ul><ul id="afa11bc0-2683-4cbe-a47a-5813f1476bda" class="bulleted-list"><li style="list-style-type:disc">Embeddings are used to represent high-dimensional image data in a continuous, dense, and lower-dimensional space. </li></ul><ul id="4f30ca65-3152-4a4f-8000-0b1d7f1c6548" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue_background"><strong>Think of the embedding as a compressed version of the patch that encodes important information. It doesn&#x27;t contain every single detail, but it captures the key aspects like overall color scheme, edges, or textures. </strong></mark><mark class="highlight-red_background"><strong>They are the Features in a Patch of size 196x1</strong></mark></li></ul></div></p><p id="92555205-ea3d-4bd3-9fe3-0b27c23c1023" class=""><mark class="highlight-blue"><code><strong>kernel_size</strong></code></mark><mark class="highlight-blue"><strong> </strong></mark><mark class="highlight-default">: Defines the size of the convolutional kernel used for extracting patches from the input images. A convolutional kernel is a matrix of weights(parameters) that is fundamental for feature extraction</mark></p><p id="e654dab6-0b6d-489c-8602-d2123bb84348" class=""><mark class="highlight-blue"><strong><code>stride</code></strong></mark><mark class="highlight-blue"><strong> </strong></mark><mark class="highlight-default"><strong>:  </strong></mark><mark class="highlight-default">Specifies the stride of the convolution operation, i.e., the number of pixels by which the kernel moves during each step. Determines the spacing between adjacent patches in the input image.</mark></p><p id="d808b64f-8738-4c6c-b218-f167709e0780" class=""><mark class="highlight-blue"><strong><code>padding</code></strong></mark><mark class="highlight-blue"><strong> :</strong></mark><mark class="highlight-default"> Specifies the amount of zero-padding added to the input image borders before applying the convolution operation.</mark></p><p id="3d083598-339c-46f9-b8d9-4426e15d5cf3" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2d44a6a0-2a53-4055-94ca-c3526e9a0d62"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%"><mark class="highlight-teal"><strong><code>Convolution Layer </code></strong></mark><ul id="c94c07b3-d72c-4962-b8e9-31c1d164b78e" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-gray_background">a convolution layer is used for feature extraction. they have convolution kernels which  are the fundamentals, itâ€™s a matrix of weights that slides accross the input data </mark></li></ul><ul id="2972580a-7086-44c0-aa4e-e8207d126ef2" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-gray_background">At each position the kernel computes a dot product between its weights and the values in its receptive field (a local region of the input).</mark></li></ul><ul id="e4de51f4-7b73-4e85-b805-76e8ea29d514" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-gray_background">This dot product operation aggregates information from the input data, emphasizing certain patterns or features that match the weights of the kernel.</mark></li></ul><ul id="117210d8-03d0-4183-8dfe-550cc920d8da" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-gray_background"> In early layers of a CNN, kernels may detect simple features like edges, corners, or textures. As the network progresses, higher-level kernels can detect more complex and abstract features, such as object parts or semantic structures.</mark></li></ul><ul id="375ea1d8-d1dc-4cb2-8e49-92afa6d4939f" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-gray_background">During the training process, the weights of the convolutional kernels are learned via backpropagation and gradient descent.</mark></li></ul><ul id="fc9c1f69-79ef-46f9-ae52-ef62b5b588aa" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-gray_background">The network adjusts the weights based on the loss function and the gradients of the loss with respect to the weights, optimizing the kernels to extract relevant features that minimize the prediction error.</mark></li></ul><figure id="f49a752b-1c5f-4546-a45d-238d92a20afc" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Output</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>âˆ‘</mo><mrow><mi>c</mi><mo>=</mo><mn>0</mn></mrow><mn>2</mn></munderover><mrow><mo fence="true">(</mo><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>15</mn></munderover><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mn>15</mn></munderover><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo>+</mo><mi>j</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>â‹…</mo><mi>K</mi><mo stretchy="false">(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Output}(x, y) = \sum_{c=0}^{2} \left( \sum_{i=0}^{15} \sum_{j=0}^{15} I(x+i, y+j, c) \cdot K(i, j, c) \right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Output</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.2149em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">15</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">15</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">â‹…</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span></span></div></figure><p id="11b26324-d09f-43f3-a91f-5490a5e63fef" class=""><mark class="highlight-purple"><code><strong>I</strong></code></mark> is the input image matrix and the <mark class="highlight-purple"><code><strong>K</strong></code></mark> is the kernel matrix and <mark class="highlight-purple"><code><strong>c</strong></code></mark> are the number of color channels</p><ul id="22adb699-181f-4997-a9a3-ad56ba2da7cd" class="bulleted-list"><li style="list-style-type:disc">The output size calculation for the patch <mark class="highlight-purple"><code><strong>s</strong></code></mark><mark class="highlight-purple"><strong>  </strong></mark>is the stride of the convolution </li></ul><figure id="93eedcd0-b160-4c52-992d-c757e4acf12e" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>H</mi><mtext>out</mtext></msub><mo>=</mo><mrow><mo fence="true">âŒŠ</mo><mfrac><mrow><mi>H</mi><mo>âˆ’</mo><mi>k</mi></mrow><mi>s</mi></mfrac><mo fence="true">âŒ‹</mo></mrow><mo>+</mo><mn>1</mn><mo>=</mo><mrow><mo fence="true">âŒŠ</mo><mfrac><mrow><mn>224</mn><mo>âˆ’</mo><mn>16</mn></mrow><mn>16</mn></mfrac><mo fence="true">âŒ‹</mo></mrow><mo>+</mo><mn>1</mn><mo>=</mo><mn>14</mn></mrow><annotation encoding="application/x-tex">H_{\text{out}} = \left\lfloor \frac{H - k}{s} \right\rfloor + 1 = \left\lfloor \frac{224 - 16}{16} \right\rfloor + 1 = 14</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">âŒŠ</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">âŒ‹</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">âŒŠ</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">16</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">224</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">16</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">âŒ‹</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">14</span></span></span></span></span></div></figure><figure id="c55eb3d6-2deb-491a-8a16-a2a2b4e9ec06" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mtext>out</mtext></msub><mo>=</mo><mrow><mo fence="true">âŒŠ</mo><mfrac><mrow><mi>W</mi><mo>âˆ’</mo><mi>k</mi></mrow><mi>s</mi></mfrac><mo fence="true">âŒ‹</mo></mrow><mo>+</mo><mn>1</mn><mo>=</mo><mrow><mo fence="true">âŒŠ</mo><mfrac><mrow><mn>224</mn><mo>âˆ’</mo><mn>16</mn></mrow><mn>16</mn></mfrac><mo fence="true">âŒ‹</mo></mrow><mo>+</mo><mn>1</mn><mo>=</mo><mn>14</mn></mrow><annotation encoding="application/x-tex">W_{\text{out}} = \left\lfloor \frac{W - k}{s} \right\rfloor + 1 = \left\lfloor \frac{224 - 16}{16} \right\rfloor + 1 = 14</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">âŒŠ</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">âŒ‹</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">âŒŠ</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">16</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">224</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">16</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">âŒ‹</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">14</span></span></span></span></span></div></figure></div></figure><p id="3f7ed04e-9ca8-407a-9e6e-f8233ed6f432" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="57703276-e618-4ed8-ba6b-4e39f449dccc"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%">layers in Patch Embedding: They are instances of Conv2d</div></figure><blockquote id="b06a9654-62cf-47dd-8eb0-fe7d8d31bfb5" class="">Before patching, the height and width refer to the dimensions of the input image in pixels and after patching, height and width refer to the number of patches along the respective dimensions of the original image</blockquote><p id="439e8fd2-5aa8-49a3-8e43-fc49d64c9016" class="">
</p><p id="d0de444e-eafc-4454-b0b7-6d182bf969bb" class=""><mark class="highlight-red"><strong><code>patcher</code></strong></mark>  : Enables the transformation of input images into patch-based embeddings, helping the extraction of spatial information at different scales. Each patch represents a localized region of the image</p><p id="b4920f4c-72cc-4596-89e6-f68cdd25de4a" class="">example Input Image: An image of shape <code>[batch_size, in_channels, height, width]</code> (e.g., <code>[32, 1, 224, 224]</code> f</p><ul id="36aaefe3-aae5-406d-a055-ec2e9bea97ec" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><strong><code>self.patcher</code></strong></mark>: An instance variable that holds the convolutional layer.</li></ul><ul id="d73e5232-09fd-43c8-83fe-86ab2c02c775" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>nn.Conv2d</strong></code></mark>: A 2D convolutional layer from PyTorch&#x27;s neural network module.<ul id="976d85f8-f464-4cdf-bf7f-f999fab7fef6" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>in_channels</strong></code></mark>: The number of channels in the input image (e.g., 1 for grayscale).</li></ul><ul id="a6583f91-c93f-453e-8fbe-66d1d86e4140" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>out_channels</strong></code></mark>: The number of output channels, which is set to <mark class="highlight-blue"><code>embedding_dim</code></mark>. This means each patch will be represented by a vector of this dimension.</li></ul><ul id="c09b42e3-c298-4b38-8b57-decc2465902b" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>kernel_size</strong></code></mark>: The size of the convolutional kernel, which is set to <mark class="highlight-blue"><code>patch_size</code></mark>. This determines the size of each patch.</li></ul><ul id="de3b17b9-6fd2-4e55-b519-fa79a2ce2e2a" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>stride</strong></code></mark>: The step size of the convolutional kernel, also set to <mark class="highlight-blue"><code>patch_size</code></mark>, ensuring non-overlapping patches.</li></ul><ul id="a9125ffd-339d-47b6-8ed7-bf8016ada19c" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>padding</strong></code></mark>: Amount of zero-padding added to both sides of the input. It&#x27;s set to 0, meaning no padding is added.</li></ul></li></ul><p id="217eef1d-cd91-48f3-9e18-adc185e9339a" class="">After patching,</p><figure id="f6582a7e-b47c-4287-b60e-548afaa7059b" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>h</mi><mi>a</mi><mi>p</mi><mi>e</mi><mo>:</mo><mo stretchy="false">[</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator="true">,</mo><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi mathvariant="normal">_</mi><mi>y</mi><mo separator="true">,</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi mathvariant="normal">_</mi><mi>x</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Shape: [batch\_size, embedding\_dim, num\_patches\_y, num\_patches\_x]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">ha</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">[</span><span class="mord mathnormal">ba</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">d</span><span class="mord mathnormal">im</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">es</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">es</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">x</span><span class="mclose">]</span></span></span></span></span></div></figure><ul id="d713923d-9d5e-44ce-8e35-2b55b427408e" class="bulleted-list"><li style="list-style-type:disc">Example: <mark class="highlight-default"><strong><code>[32,768,14,14]   as 224 (initial width(or) height) / 16(patch size) = 14</code></strong></mark></li></ul><blockquote id="cd6a0867-1207-4889-9955-c12b9934ef9c" class="">Image (224x224x3)<br/>+-----------------+<br/>|                           |<br/>|    (224x224x3)    |<br/>|                           |<br/>+-----------------+<br/></blockquote><blockquote id="92d8957e-55cb-4042-9a65-cfc155c3e2dd" class="">After dividing into 16x16 patches:</blockquote><blockquote id="f6003531-e964-4f58-8085-6d9e471d4581" class="">+---------+---------+---------+---------+<br/>| (16x16x3)| (16x16x3)| ...     | (16x16x3)  |<br/>| Patch 1    | Patch 2   |  ...     | Patch 14   |<br/>+---------+---------+---------+---------+<br/>| (16x16x3)| (16x16x3) | ...     | (16x16x3) |<br/>| Patch 15  | Patch 16  | ...    | Patch 28    |<br/>+---------+---------+---------+---------+<br/>| ...     | ...     | ...     | ...     |<br/>+---------+---------+---------+---------+<br/>| (16x16x3) | (16x16x3) |  ...    | (16x16x3) |<br/>| Patch 183 | Patch 184 | ...     | Patch 196|<br/>+---------+---------+---------+---------+<br/></blockquote><blockquote id="8af6a75a-70a0-4f14-a9c5-668195b1e9dc" class="">Flatten each patch (16x16x3) to (768):</blockquote><blockquote id="6b7599a3-cbbc-4564-a34d-5ff239fe88af" class="">Patch 1: [p11, p12, p13, ..., p1768]<br/>Patch 2: [p21, p22, p23, ..., p2768]<br/>...<br/>Patch 196: [p1961, p1962, p1963, ..., p196768]<br/></blockquote><hr id="3e023a0b-c2a1-4887-8c1d-698da1f84971"/><p id="a0fdd648-f812-4e5f-a8e5-99a5c0ae02c4" class=""><strong><code>flatten</code></strong><strong> : </strong>The <mark class="highlight-blue"><code>flatten</code></mark> layer reshapes the output of the convolutional layer (<mark class="highlight-blue"><code>patcher</code></mark>) into a 1D sequence. After the patches are extracted and processed by the convolutional layer, they are flattened into a single dimension. </p><p id="bd5b55e6-2ab3-4e13-8922-64d5f930ead7" class="">it will modify the  [batch\_size, embedding\_dim, num_patches_y, num_patches_x] </p><p id="4d09371f-c6e4-45d0-8d82-111351314b7c" class=""><mark class="highlight-purple"><code>start_dim = 2,end_dim = 3</code></mark><mark class="highlight-purple"> </mark><mark class="highlight-default">This will flatten the image from num_patches_x to num_patches_y</mark></p><p id="6b5abc54-3c66-4ae5-990f-baf24f7c1af6" class="">it will flattens the patch dimensions (14,14) into a single dimension</p><p id="ee57c8ca-900a-4540-a13e-e98a93770869" class="">after flattening, the shape is <mark class="highlight-default"><strong><code>[32,768,196]   (14*14 = 196) </code></strong></mark></p><figure id="b22df7ad-d19d-46c2-b7dd-bf240af0e721" class="image"><a href="LLM%20Vision%20Transformers%20a87c07d6e350428db36a8c325308fa43/Picture1.png"><img style="width:576px" src="LLM%20Vision%20Transformers%20a87c07d6e350428db36a8c325308fa43/Picture1.png"/></a></figure><hr id="07403222-6405-4131-91ec-8ac725294c17"/><blockquote id="ba838ed4-f546-4d8d-bfbe-291936407d27" class=""><strong>Linear Projection:</strong> Here, a simple linear layer is applied to the flattened pixels of each patch. This layer acts like a filter, transforming the high-dimensional pixel values into a lower-dimensional vector. The size of this vector determines the amount of information captured from the patch.</blockquote><h2 id="e9b1f666-3efc-46cd-b5ba-00df6789b7e9" class="">def forward()</h2><p id="99b60908-6143-43f2-93b9-64727675db71" class=""><strong>Input</strong>: A batch of images of shape <mark class="highlight-red"><strong><code>[batch_size, in_channels, height, width]</code></strong></mark></p><p id="3da217e9-9399-42b6-b949-a8ed515470ce" class=""><mark class="highlight-red"><code><strong>[ 32 , 3 , 224, 224 ]</strong></code></mark></p><p id="94523651-08c8-4111-a3b6-28694bcfdc06" class="">it then gets the width or height of the image as image resolution as both are 224 , 224</p><p id="7c37191d-9e9b-4f95-bd77-2dfadfdcc169" class="">we check the condition that image resolution is divisible by the patch size  i.e  224 % 16 ==0 or nor</p><h3 id="eaa4b2d4-7f91-46c9-9567-238d623edbd2" class="">Reason for Assertion in the <mark class="highlight-teal"><code>forward</code></mark> Method</h3><ol type="1" id="84f536ae-748c-431b-a6cf-6864e562f787" class="numbered-list" start="1"><li><strong>Safety Check</strong>:<ul id="17c8d026-265f-4d85-9bff-2b55c5fc751a" class="bulleted-list"><li style="list-style-type:disc">The assertion serves as a safety check to ensure that the input images to the <strong><mark class="highlight-teal"><code>PatchEmbedding</code></mark></strong> layer have the correct dimensions. This is a defensive programming practice to catch potential issues early in the processing pipeline.</li></ul></li></ol><ol type="1" id="de2dd763-ce83-4464-9bb0-3b4bf60cb169" class="numbered-list" start="2"><li><strong>Robustness</strong>:<ul id="2ca101d0-3a50-449e-8e29-17e365594992" class="bulleted-list"><li style="list-style-type:disc">Even though you may have resized the images correctly using transforms, it&#x27;s still possible for unexpected inputs to slip through. For example, if another part of the code or a future modification changes the input size, this assertion will catch the discrepancy immediately.</li></ul></li></ol><p id="af2417cf-8336-4522-a865-5e4bf0f9adce" class="">Itâ€™s like a double check thatâ€™s it.</p><p id="06f8dc0d-6adc-40e1-8ff1-a24a2216a7e0" class="">
</p><ul id="188aeb98-ce47-4a1a-9dfd-da8cd03d8317" class="bulleted-list"><li style="list-style-type:disc"><strong>After Flattening</strong>: <code>[32, 768, 196]</code> (14x14 patches flattened to 196 patches).</li></ul><ul id="ff5ef15f-4832-48a3-9779-9408e3b8b789" class="bulleted-list"><li style="list-style-type:disc"><strong>After Permuting</strong>: <code>[32, 196, 768]</code> ( ready for transformer input ).</li></ul><hr id="7b104e18-9c3e-4a6e-bcf5-bcb7f79586a1"/><h1 id="f83069df-e186-411d-8016-afbbd1c3f07d" class="">Setting the Seed and checking the working of patch embedding layer</h1><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e8464a45-2ae5-4575-8a2e-1ce22bef5af4" class="code"><code class="language-Python">patch_size =16

# Set seeds
def set_seeds(seed: int=42):
    &quot;&quot;&quot;Sets random sets for torch operations.

    Args:
        seed (int, optional): Random seed to set. Defaults to 42.
    &quot;&quot;&quot;
    # Set the seed for general torch operations
    torch.manual_seed(seed)
    # Set the seed for CUDA torch operations (ones that happen on the GPU)
    torch.cuda.manual_seed(seed)

set_seeds()

# Create an instance of patch embedding layer
patchify = PatchEmbedding(in_channels=1,
                          patch_size=16,
                          embedding_dim=768)

# Pass a single image through
print(f&quot;Input image shape: {image.unsqueeze(0).shape}&quot;)
patch_embedded_image = patchify(image.unsqueeze(0)) # add an extra batch dimension on the 0th index, otherwise will error
print(f&quot;Output patch embedding shape: {patch_embedded_image.shape}&quot;)</code></pre><p id="0a3a9097-9dc5-4332-ac79-699203abb5a4" class="">
</p><p id="9709d42f-1d60-452b-b752-091c5b4f6820" class=""><mark class="highlight-red"><code><strong>setting Seed :</strong></code></mark><mark class="highlight-red"><strong> </strong></mark>it ensures reproductibility. on fixing that we ensure that everytime we run, we get the same results</p><p id="83a6a000-6bda-4594-8a8c-8017775ef8f0" class="">seed is by default <mark class="highlight-red"><strong>42</strong></mark></p><p id="49bb5029-49d2-47d5-9973-5177ac99230b" class=""><mark class="highlight-blue"><code><strong>torch.manual_seed(seed)</strong></code></mark> will set the seed for manual operations</p><p id="e2e29bc2-ccc8-4fdd-b404-6480b682b8c2" class=""><mark class="highlight-blue"><code><strong>torch.cuda.manual_seed(seed)</strong></code></mark> will set the seed for CUDA torch operations</p><hr id="dccd82d9-d57c-4173-b415-24d6d1818ed9"/><p id="39718dcf-6e7b-4da4-aa55-2b33d3d8f9d6" class=""><strong><mark class="highlight-blue"><code>image.unsqueeze(0)</code></mark></strong> :Adds an extra batch dimension to the image tensor. Neural networks in PyTorch expect the input to be in the form [batch_size, channels, height, width].</p><p id="154a4b69-272f-4da1-ad82-f54f399adc8d" class=""><mark class="highlight-blue"><code><strong>unsqueeze(0) </strong></code></mark>adds a batch dimension at the 0th index, converting the image tensor from </p><p id="960bb691-c341-44ac-8778-a260c01ebc43" class=""><code><strong>[3, 224, 224]</strong></code> to <code><strong>[1, 3, 224, 224]</strong></code><strong> </strong><div class="indented"><p id="7c5d7128-034d-4527-9a6b-98d982ef7001" class=""><code><strong>image.shape</strong></code> is [3, 224, 224] initially. After <code><strong>unsqueeze(0)</strong></code>, it becomes [1,3, 224, 224].</p></div></p><p id="af4086b0-2181-4745-9aab-899f59c38152" class="">and then that unsqueezed image is sent to patchify layer where the images are sent in forward function</p><hr id="5fd58d0e-2f24-4d41-9529-c4e22e9a0825"/><h3 id="de65b42c-425d-4971-9a7e-1086575b635d" class="">Class token </h3><hr id="4e5a6ce2-02c4-40ef-902f-5ffc8b877d6f"/><p id="653d6805-fe6e-43e4-9f77-5998d933f5d9" class="">
</p><p id="b9650222-03c3-4143-9f32-945df9daa858" class="">The class token is a special token added to the sequence of patch embeddings. It allows the model to aggregate information from all patches and use it for classification tasks.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="c41636ff-2c88-4395-974c-10bbad7e5c46"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%">The class token is typically added as the first row or element in the embedding sequence. This way, it becomes the initial representation that captures global information about the entire image. Then, the patch embeddings, which capture local information about different parts of the image, follow the class token. This arrangement allows the model to consider both global and local context when processing the image data. This class token serves as a representation of the entire image and is used by the classifier to make predictions.</div></figure><p id="8965240c-428b-4601-9319-603ac6299f02" class="">
</p><p id="a6b727ef-854a-4fa1-8085-e24da7385fa1" class=""><mark class="highlight-blue"><strong><code>nn.Parameter</code></strong></mark> is a class in PyTorch used to define parameters that are learnable by the model during training. When you define a parameter using <mark class="highlight-blue"><strong><code>nn.Parameter</code></strong></mark>, you&#x27;re essentially telling PyTorch to include this parameter in the model&#x27;s list of trainable parameters, and these parameters will be optimized (updated) by the optimizer during training.</p><p id="c86b3140-2bc4-429e-a20f-9ac3539fed36" class=""><br/><br/><mark class="highlight-blue"><strong><code>torch.ones(batch_size, 1, embedding_dimension)</code></strong></mark> creates a tensor filled with ones, representing the class token embedding.</p><p id="40d31e18-9cd1-43a6-9dbc-a2a33a111800" class="">
</p><p id="c397da05-66c0-4d9d-9f09-63b11ae539f5" class=""><strong><mark class="highlight-blue"><code>requires_grad=True</code></mark></strong> specifies that gradients with respect to this parameter should be computed during backpropagation. This means that during training, the optimization algorithm will adjust the values of this parameter based on the computed gradients, effectively learning from the data.<br/><br/></p><p id="2aada4bd-1f09-4fd0-8bc9-95f5d0e35437" class=""><strong><mark class="highlight-default"><code>patch_embedding_class_token</code></mark></strong><mark class="highlight-default"><code> = torch.cat((class_token, patch_embedding), dim=1)</code></mark></p><p id="1d389860-5e50-44d8-b7fe-790ce89fe681" class=""><br/>We want to concatenate the class token tensor with the patch embedding tensor along the second dimension <br/><code><strong>(dim=1)</strong></code>, which corresponds to the batch dimension. This means that each class token will be added as the first element of its corresponding batch of patch embeddings.<br/><br/><br/></p><p id="86e2e624-9069-4562-ae45-80aae261bebb" class="">and then positional encoding is done to all the  batch images it has the same dimension as the </p><p id="e66867ba-6bf0-4b99-8734-9d3f7ff372fc" class=""><strong><mark class="highlight-default"><code>patch_embedding_class_token</code></mark></strong> </p><p id="e9cfc4da-740a-4c82-a081-603228c5ac2e" class="">The positional encoding remains consistent across all images in the training process as well. Once initialized, the positional encoding vectors are fixed and do not change during training.</p><p id="40f1fee2-31d4-4820-b358-d4190266a28f" class="">these positional encoding values are added to the tensor</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5e183217-9141-420b-a097-2cb7e91ca5a0" class="code"><code class="language-Python"># 8. Create position embedding
number_of_patches = int((height * width) / patch_size**2)  # it will be 196
position_embedding = nn.Parameter(torch.ones(1, number_of_patches+1, embedding_dimension),
                                  requires_grad=True) # make sure it&#x27;s learnable


# 9. Add position embedding to patch embedding with class token
patch_and_position_embedding = patch_embedding_class_token + position_embedding
print(f&quot;Patch and position embedding shape: {patch_and_position_embedding.shape}&quot;)
#patch_and_position_embedding

	print(patch_embedding_class_token)  #1 is added in the beginning of each</code></pre><figure id="78b5d9bc-d9f6-4833-9107-bcd02ff01e09" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>PE</mtext><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>sin</mi><mo>â¡</mo><mrow><mo fence="true">(</mo><mfrac><mtext>pos</mtext><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mtext>768</mtext></mfrac></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{PE}_{(pos, 2i)} = \sin\left(\frac{{\text{pos}}}{{10000^{\frac{{2i}}{{{\text{768}}}}}}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0385em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord text"><span class="mord">PE</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mop">sin</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.1629em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9471em;"><span style="top:-3.3486em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8551em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">768</span></span></span></span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord text"><span class="mord">pos</span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.8371em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></div></figure><figure id="b9697cce-2ef7-416e-a03f-10122977880e" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>PE</mtext><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>cos</mi><mo>â¡</mo><mrow><mo fence="true">(</mo><mfrac><mtext>pos</mtext><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mtext>768</mtext></mfrac></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{PE}_{(pos, 2i + 1)} = \cos\left(\frac{{\text{pos}}}{{10000^{\frac{{2i}}{{{\text{768}}}}}}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0385em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord text"><span class="mord">PE</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mop">cos</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.1629em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">1000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9471em;"><span style="top:-3.3486em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8551em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">768</span></span></span></span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord text"><span class="mord">pos</span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.8371em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></div></figure><hr id="895b0c98-a167-4739-9480-48064ed35ca7"/><h1 id="6f75fb3c-5759-408c-8d43-84a9ccb9dc65" class="">Multi Head Self-Attention Block</h1><hr id="ab7feddd-b39b-4ead-9fbe-bf6f3dd0bdc9"/><p id="1513bfea-c031-4f74-b2de-a649e6104823" class="">This block allows the model to focus on different parts of the input sequence (in this case, image patches) and compute context-aware representations for each patch. It achieves this by attending to different parts of the input sequence simultaneously using multiple attention heads.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9f9164b4-fec8-49dc-b76d-50034e4194b1" class="code"><code class="language-Python">class MultiheadSelfAttentionBlock(nn.Module):
    &quot;&quot;&quot;Creates a multi-head self-attention block (&quot;MSA block&quot; for short).
    &quot;&quot;&quot;
    # 2. Initialize the class with hyperparameters from Table 1
    def __init__(self,
                 embedding_dim:int=768, # Hidden size D from Table 1 for ViT-Base
                 num_heads:int=12, # Heads from Table 1 for ViT-Base
                 attn_dropout:float=0): # doesn&#x27;t look like the paper uses any dropout in MSABlocks
        super().__init__()

        # 3. Create the Norm layer (LN)
        self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)

        # 4. Create the Multi-Head Attention (MSA) layer
        self.multihead_attn = nn.MultiheadAttention(embed_dim=embedding_dim,
                                                    num_heads=num_heads,
                                                    dropout=attn_dropout,
                                                    batch_first=True) # does our batch dimension come first?

    # 5. Create a forward() method to pass the data throguh the layers
    def forward(self, x):
        x = self.layer_norm(x)
        attn_output, _ = self.multihead_attn(query=x, # query embeddings
                                             key=x, # key embeddings
                                             value=x, # value embeddings
                                             need_weights=False) # do we need the weights or just the layer outputs?
        return attn_output</code></pre><p id="b90694ef-48ed-4e8a-9241-37d9e8d7397c" class="">
</p><h3 id="bf7b029c-f2b1-438a-8d53-e0c43e6c3c1f" class="">Layer_norm   â€”&gt; it stabilizes the training process!</h3><h3 id="84e9d216-37f0-4628-9e5d-c86f0e0c8e4a" class="">What Does Layer Normalization Do?</h3><p id="0ffa041a-9bb4-4c1f-9ba3-ce8b8739e345" class="">Layer normalization normalizes the input across the features for each data point independently. This means it ensures that the inputs have a mean of 0 and a standard deviation of 1 across each feature, which helps stabilize and speed up the training process.</p><p id="bdb866b1-1db8-4bf3-8b9c-6c6e83690337" class=""><code><strong>normalized_shape</strong></code>: This is the shape of the input tensor that will be normalized. In this case, it is set to <strong><code>embedding_dim</code></strong>, meaning it normalizes across the features of the embedding. as you need the whole features to be accounted in normalization kadhaaaa! anduke adi also embedd_dim</p><h3 id="4d226ac1-7248-4443-8555-51167189fc4a" class="">What Does Layer Normalization Do to the Input Image?</h3><p id="39fb054f-3cea-4454-be77-35b5fe2214f3" class="">When you pass an input through the layer normalization, it scales the input data so that the mean of the data becomes 0 and the variance becomes 1 for each feature (each dimension of the embedding). This is particularly important in deep learning because it helps mitigate the problem of internal covariate shift, where the distribution of each layer&#x27;s inputs changes during training, slowing down the training process.</p><figure id="e800066b-8e5a-4cc9-a441-7daeda48581a" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Î¼</mi><mrow><mo stretchy="false">(</mo><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi></mrow><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu{ (or)} {mean} = \frac{1}{m} \sum_{i=1}^{m} x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Î¼</span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mclose">)</span></span><span class="mord"><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">an</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">m</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div></figure><figure id="dcabddbc-ead6-4d21-9612-859b8d18a933" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Ïƒ</mi><mrow><mo stretchy="false">(</mo><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>r</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>âˆ’</mo><mi>Î¼</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mi>Ïµ</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma 
{(or)} {standard\_deviation} = \sqrt{\frac{1}{m} \sum_{i=1}^{m} (x_i - \mu)^2 + \epsilon}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mclose">)</span></span><span class="mord"><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">ia</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1568em;vertical-align:-1.2777em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791em;"><span class="svg-align" style="top:-5.1168em;"><span class="pstrut" style="height:5.1168em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">m</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">Î¼</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">Ïµ</span></span></span><span style="top:-3.8391em;"><span class="pstrut" style="height:5.1168em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.1968em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='3.1968em' viewBox='0 0 400000 3196' preserveAspectRatio='xMinYMin slice'><path d='M702 80H40000040
H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1
h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170
c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667
219 661 l218 661zM702 80H400000v40H742z'/></svg></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span></span></span></span></span></div></figure><figure id="7f51b960-1023-4c28-bcb2-8c49ca9f95c0" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi>x</mi><mo>^</mo></mover><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>âˆ’</mo><mi>Î¼</mi></mrow><mi>Ïƒ</mi></mfrac></mrow><annotation encoding="application/x-tex">\hat{x}_i   = \frac{x_i - \mu}{\sigma}   </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.9463em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">Î¼</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div></figure><h3 id="5f98559c-5165-40ed-a100-365b17c5f15a" class="">What Happens If You Don&#x27;t Use Layer Normalization?</h3><p id="6fb3c3df-092c-4ab7-8e04-b83d909fc53a" class="">Without layer normalization, the training process can become unstable. The model might take much longer to converge because the distribution of inputs to each layer keeps changing, which makes it harder for the network to learn. Moreover, it can also lead to vanishing or exploding gradients, making it difficult for the model to train effectively.</p><p id="4b17bbe2-9a12-4680-90bc-45b16d2c2dee" class="">
</p><p id="e8505d2c-5517-4ced-a494-83b9427380db" class="">In Normalization, it subtracts the feature value from the mean, and divides it with the standard deviation it returns the same input tensor but applying the transformations inplace</p><p id="3377bb4e-0a65-405e-991e-8b1208433754" class=""> </p><hr id="b58a15d0-01c0-4da5-b387-06e712b575c7"/><h2 id="86234080-f3fb-40a5-b728-26428bf18115" class="">Multi Head Attention</h2><hr id="200bf422-6a2f-4260-9360-68d2831d3773"/><p id="144821e3-bd54-495e-b563-f267b98ee26b" class="">The main purpose of multi-head self-attention is to allow the model to consider multiple relationships and dependencies within the input sequence at different positions simultaneously. This is particularly useful for capturing complex patterns and interactions in data.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="61f9f62b-054a-4288-95f8-0375b7a7d67a"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%"><strong>Self-Attention Mechanism</strong></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="ac4eb6ff-4c0d-47dc-9e51-a6df2b9f307b"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%">Self-attention, or scaled dot-product attention, computes a weighted sum of the input values, where the weights are derived from the similarity between a query and key. Here&#x27;s a step-by-step</div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="590680b6-bb69-4e97-92f3-3d31ffb2c1e3"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%">Each input token (e.g. a patch in ViT) is embedded into a vector of a fixed dimension. Let&#x27;s denote the input sequence as <code>X</code>, which has a shape of <mark class="highlight-teal"><strong><code>(batch_size, patch_size, embedding_dim)</code></strong></mark><mark class="highlight-teal">.</mark></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="cd1d35c6-1b2f-4b73-8e1d-c226b54b8ee1"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%"> 1.  The input embeddings are linearly projected into three different spaces to create the Query (Q), Key (K), and Value (V) matrices. These are obtained by multiplying <code>X</code> with learned weight matrices <mark class="highlight-teal"><code><strong>W_Q</strong></code></mark>, <mark class="highlight-teal"><code><strong>W_K</strong></code></mark>, and <mark class="highlight-teal"><code><strong>W_V</strong></code></mark>: the matrices are initially initialized with random values and learnt during the backpropagation<figure id="a4b10b7e-5bbd-4d0c-b949-9113ce57b6c1" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub><mo separator="true">,</mo><mspace width="1em"/><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub><mo separator="true">,</mo><mspace width="1em"/><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></mrow><annotation encoding="application/x-tex">Q = XW_Q, \quad K = XW_K, \quad V = XW_V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div></figure><ol type="1" id="08a465c8-68b3-496b-8022-e8befd9e9e31" class="numbered-list" start="2"><li> The shapes of <mark class="highlight-teal"><strong><code>Q</code></strong></mark>, <mark class="highlight-teal"><strong><code>K</code></strong></mark>, and <mark class="highlight-teal"><strong><code>V</code></strong></mark> are all <mark class="highlight-teal"><strong><code>(batch_size, patches(196) , embedding_dim)</code></strong></mark>.</li></ol></div></figure><figure id="a6564749-2942-4d0e-847b-938698dd951c" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>T</mi><mi>h</mi><mi>u</mi><mi>s</mi><mo separator="true">,</mo><msub><mi>W</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>Q</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>v</mi></msub><mo separator="true">,</mo><mi>m</mi><mi>u</mi><mi>s</mi><mi>t</mi><mi>h</mi><mi>a</mi><mi>v</mi><mi>e</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>h</mi><mi>a</mi><mi>p</mi><mi>e</mi><mo>=</mo><mo stretchy="false">(</mo><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>m</mi><mo separator="true">,</mo><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Thus, W_k,W_Q,W_v, must have the shape= (embedding\_dim, embedding\_dim)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">h</span><span class="mord mathnormal">u</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">u</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ha</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">es</span><span class="mord mathnormal">ha</span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">(</span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">d</span><span class="mord mathnormal">im</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">d</span><span class="mord mathnormal">im</span><span class="mclose">)</span></span></span></span></span></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="4a3d445f-38dd-49a0-9cc9-098adddbf600"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%">The attention scores are computed by taking the dot product of the query with all keys, scaling by the square root of the embedding dimension to stabilize gradients, and applying a softmax to obtain the weights:<figure id="c266d275-78e4-4e36-8915-8b71d8791554" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{softmax}\left(\frac{Q_iK_j^T}{\sqrt{d_k}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6261em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7848em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span></span></div></figure><ul id="7d0ddc0c-d857-4730-8bfc-cdbfd19c65bf" class="bulleted-list"><li style="list-style-type:disc">Here, d_k is the dimension of the keys (equal to the embedding dimension divided by the number of heads in multi-head attention). </li></ul><ul id="73e9930f-60fe-440d-8143-eb9227d6e2ad" class="bulleted-list"><li style="list-style-type:disc">This score determines how much attention patch <mark class="highlight-purple"><code><strong>i</strong></code></mark> should pay to patch <mark class="highlight-purple"><code><strong>j</strong></code></mark></li></ul></div></figure><figure id="fd661b88-49d2-471d-8b31-f674e281df01" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnspacing="1em"><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>Ïƒ</mi><mo stretchy="false">(</mo><mi mathvariant="bold">z</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>z</mi><mi>i</mi></msub></msup><mrow><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mi>e</mi><msub><mi>z</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{equation}\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^n e^{z_j}}\end{equation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4715em;vertical-align:-0.9858em;"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4858em;"><span style="top:-3.4858em;"><span class="pstrut" style="height:3.3414em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span><span class="mopen">(</span><span class="mord mathbf">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.3057em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">âˆ‘</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.1301em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.9858em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4858em;"><span style="top:-3.4858em;"><span class="pstrut" style="height:3.3414em;"></span><span class="eqn-num"></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.9858em;"><span></span></span></span></span></span></span></span></span></div></figure><hr id="87d410d5-f6b0-40cc-809a-219d979de40d"/><p id="8dcb5b2c-be79-4765-ac55-fbe04796e863" class="">Multi-head attention extends this mechanism by running multiple self-attention operations (or heads) in parallel. Each head has its own set of learned weights, allowing it to focus on different parts of the sequence</p><blockquote id="d0975bc2-6972-4ecf-aa73-e5b69994a6f7" class="">Better!<ul id="470ec699-d696-4010-834d-6c95f5a576c9" class="bulleted-list"><li style="list-style-type:disc"><strong>Multiple Heads</strong>:<ul id="ca391469-f2a5-4a13-bedf-776a11509568" class="bulleted-list"><li style="list-style-type:circle">Split the embedding dimension into multiple smaller dimensions. For example, if <code>embedding_dim</code> is 768 and <code>num_heads</code> is 12, each head works with an embedding dimension of 64. <figure id="273771ce-b3d3-4fbe-82bd-c0deae8dcd2b" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>64</mn><mo>=</mo><mfrac><mn>768</mn><mn>12</mn></mfrac></mrow><annotation encoding="application/x-tex">64 = \frac{768}{12}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">64</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">12</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">768</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div></figure></li></ul></li></ul><ul id="992e5e2c-8ba3-40ad-8374-635cd4d235be" class="bulleted-list"><li style="list-style-type:disc"><strong>Parallel Self-Attention</strong>:<ul id="4c7717f2-c84d-4b17-a9ff-3f84cf2e6c35" class="bulleted-list"><li style="list-style-type:circle">Each head performs its own self-attention calculation on the smaller embedding dimension:<figure id="2f4c77e5-d612-4914-a3a3-c1b5ec2f85b8" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>Head</mtext><mi>i</mi></msub><mo>=</mo><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mi>i</mi><mo separator="true">,</mo><mi>K</mi><mi>i</mi><mo separator="true">,</mo><mi>V</mi><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Head}_i=Attention(Qi,Ki,Vi)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord">Head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">Vi</span><span class="mclose">)</span></span></span></span></span></div></figure></li></ul><ul id="b9f94158-16c1-48b8-b479-e15506180823" class="bulleted-list"><li style="list-style-type:circle">These heads capture different aspects of the relationships in the input data.</li></ul></li></ul><ul id="4c76000b-43fb-4e4b-9275-9cfcfc3b8e8a" class="bulleted-list"><li style="list-style-type:disc"><strong>Concatenation and Final Linear Layer</strong>:<ul id="7ba4cb93-2dba-4db2-8695-8b9ebae5c420" class="bulleted-list"><li style="list-style-type:circle">The outputs of all heads are concatenated and passed through a final linear layer to produce the final output:<figure id="fa25f719-4ea5-405e-9430-9a66c4749573" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>i</mi><mi>H</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">(</mo><mi>H</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>H</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>â€¦</mo><mo separator="true">,</mo><mi>H</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>n</mi></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mi>O</mi></msub></mrow><annotation encoding="application/x-tex">MultiHead(Q,K,V)=Concat(Head_1,Head_2,â€¦,Head_n)W_O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">u</span><span class="mord mathnormal">lt</span><span class="mord mathnormal">i</span><span class="mord mathnormal">He</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">He</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">He</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">â€¦</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">He</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></div></figure></li></ul><ul id="2447059e-9ed7-4086-9a29-408cc1884f91" class="bulleted-list"><li style="list-style-type:circle">Here, WO is a learned weight matrix that combines the outputs of all heads.</li></ul></li></ul></blockquote><p id="40af1af8-1f79-4185-b82b-8298de282c11" class="">
</p><h3 id="8bb741a1-f3b7-42e8-b012-70f445a6e7af" class=""><strong><code><mark class="highlight-blue">attn_dropout</mark></code></strong></h3><p id="73bc54f8-8e14-4789-b922-8da9d831fb15" class="">Attn_dropout in self-attention randomly drops some attention scores during training. This helps prevent the model from relying too much on specific patterns, improving its ability to handle new data in the future (generalization). It&#x27;s like randomly forgetting some connections to learn more robust ones. itâ€™s value is generally in terms of float, which represents the percentage of dropout</p><p id="1f95444e-dbe7-4e2f-b699-4b7744487183" class=""><strong><mark class="highlight-default"><code>Attn_dropout (attention dropout) is a trick used in self-attention models. During training, it randomly forgets some connections between parts of the data. This prevents the model from becoming too reliant on specific patterns and helps it learn more generalizable knowledge. It&#x27;s like studying with flashcards, but sometimes hiding a few to force you to understand the bigger picture.</code></mark></strong></p><p id="9cf22a5f-2b55-4a24-a2bb-2528e112dece" class="">
</p><h3 id="aca50a27-b6c1-4daf-b112-fde568eceb69" class=""><mark class="highlight-blue"><code>need_weights</code></mark></h3><ul id="02916e69-f333-489c-b5d8-34d3c2cc241b" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>need_weights=True</strong></code></mark><mark class="highlight-blue">:</mark><ul id="de8b11fe-be37-453c-afa2-11b814a7cffb" class="bulleted-list"><li style="list-style-type:circle">When <mark class="highlight-blue"><code>need_weights</code></mark> is set to <mark class="highlight-blue"><code>True</code></mark>, the <mark class="highlight-blue"><code>MultiheadAttention</code></mark> layer returns a tuple: <strong><mark class="highlight-teal"><code>(attn_output, attn_weights)</code></mark></strong>.</li></ul><ul id="11ffd267-286f-4c8b-b29e-cd7b53f82cb5" class="bulleted-list"><li style="list-style-type:circle"><strong><mark class="highlight-teal"><code>attn_output</code></mark></strong>: The output of the attention mechanism, which is the transformed input sequence.</li></ul><ul id="989d5881-5e90-46d3-a3e9-2eddfb1c0fde" class="bulleted-list"><li style="list-style-type:circle"><strong><mark class="highlight-teal"><code>attn_weights</code></mark></strong>: The attention weights, which indicate how much each token attends to every other token in the sequence.</li></ul><ul id="35b336fa-0207-4a6b-91f2-28de19364183" class="bulleted-list"><li style="list-style-type:circle">Use Case: This is useful when you want to visualize or further analyze the attention patterns to understand how the model is making decisions.</li></ul></li></ul><ul id="88f0a148-0502-4fda-ad45-11d91f64f443" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>need_weights=False</strong></code></mark><mark class="highlight-blue">:</mark><ul id="6f021948-2949-4454-93c5-5ae37834c73a" class="bulleted-list"><li style="list-style-type:circle">When <mark class="highlight-blue"><code>need_weights</code></mark> is set to <mark class="highlight-blue"><code>False</code></mark>, the <mark class="highlight-blue"><code>MultiheadAttention</code></mark> layer returns only the <strong><mark class="highlight-teal"><code>attn_output</code></mark></strong>.</li></ul><ul id="4b87f7ce-a915-491c-a018-85cca468a13f" class="bulleted-list"><li style="list-style-type:circle">Use Case: This is useful when you are only interested in the output of the attention mechanism and do not need the attention weights for further analysis or visualization.</li></ul></li></ul><hr id="03c0190b-cd1f-4c87-b483-4a060476722f"/><h1 id="dfb37161-7865-4f11-b344-2dd5f884b75d" class="">MLP Block</h1><hr id="cbec39d6-9eac-4343-9fc1-5441c0d0b09a"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2d8d9e68-15e1-4ab5-ac40-051215ae2972" class="code"><code class="language-Python"># 1. Create a class that inherits from nn.Module
class MLPBlock(nn.Module):
    &quot;&quot;&quot;Creates a layer normalized multilayer perceptron block (&quot;MLP block&quot; for short).&quot;&quot;&quot;
    # 2. Initialize the class with hyperparameters from Table 1 and Table 3
    def __init__(self,
                 embedding_dim:int=768, # Hidden Size D from Table 1 for ViT-Base
                 mlp_size:int=3072, # MLP size from Table 1 for ViT-Base
                 dropout:float=0.1): # Dropout from Table 3 for ViT-Base
        super().__init__()

        # 3. Create the Norm layer (LN)
        self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)

        # 4. Create the Multilayer perceptron (MLP) layer(s)
        self.mlp = nn.Sequential(
            nn.Linear(in_features=embedding_dim,
                      out_features=mlp_size),
            nn.GELU(), # &quot;The MLP contains two layers with a GELU non-linearity (section 3.1).&quot;
            nn.Dropout(p=dropout),
            nn.Linear(in_features=mlp_size, # needs to take same in_features as out_features of layer above
                      out_features=embedding_dim), # take back to embedding_dim
            nn.Dropout(p=dropout) # &quot;Dropout, when used, is applied after every dense layer..&quot;
        )

    # 5. Create a forward() method to pass the data throguh the layers
    def forward(self, x):
        x = self.layer_norm(x)
        x = self.mlp(x)
        return x</code></pre><p id="ca584c24-13b1-4e58-9e7d-81fee47aefcb" class=""><br/>The <br/><mark class="highlight-default"><code><strong>MLPBlock</strong></code></mark> is used in Vision Transformers to process the output of the self-attention mechanism. After the multi-head self-attention block, the <mark class="highlight-default"><code><strong>MLPBlock</strong></code></mark> helps in further transforming the data through a feed-forward neural network, adding non-linearity and enabling the model to learn more complex representations.<br/><br/></p><p id="57e9368c-6cf2-4131-b217-c3eeb30a8550" class="">Multi-layer perception is also known as MLP. It is fully connected dense layers, which transform any input dimension to the desired dimension. A multi-layer perception is a neural network that has multiple layers. To create a neural network we combine neurons together so that the outputs of some neurons are inputs of other neurons.</p><blockquote id="eb776b69-6e3a-4a30-933c-156d9d3bec78" class="">Each neuron has weights and biases <br/><br/><mark class="highlight-purple"><code><strong>weight </strong></code></mark>: how much influence each input has on the output neuron<br/>Each connection from the previous layer to the neuron in the current layer has an associated weight, these are learnt during training<br/><br/><mark class="highlight-purple"><code><strong>bias</strong></code></mark> : this is the additional parameter which shifts the output of the neuron to increase model flexibility. Bias is something that adjusts the weighted sum of inputs before any activation function<br/><br/><mark class="highlight-purple"><code><strong>Connections</strong></code></mark> in FC layers are the links between neurons in consecutive layers. Each connection carries a weight, representing how strongly one neuron influences another.</blockquote><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="3f52ea7b-bd07-44fc-823c-65779ef41e33"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%"><mark class="highlight-purple"><code><strong>Layer</strong></code></mark><mark class="highlight-purple"><strong> </strong></mark>: A layer in neural network is a collection of neurons or units that process input data and produce output. In a neural network, a layer takes input data, processes it with mathematical operations (like a filter), and produces output data. Each layer learns to detect patterns (like edges in images) and passes its output to the next layer for further processing, creating complex understanding. the below is the Output of a neuron</div></figure><figure id="6e25a8ef-6bd1-4118-a35f-1325e88cc4cf" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mi>f</mi><mrow><mo fence="true">(</mo><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>x</mi><mi>j</mi></msub><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">y_i = f\left(\sum_{j=1}^{N} w_{ij} x_j + b_i\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.2421em;vertical-align:-1.4138em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span></span></div></figure><figure id="be98ce45-4085-4b0f-b2d8-b08be1e594f8" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">W</mi><mi mathvariant="bold">x</mi><mo>+</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{y} = f(\mathbf{W} \mathbf{x} + \mathbf{b})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathbf">Wx</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathbf">b</span><span class="mclose">)</span></span></span></span></span></div></figure><ul id="8a0277e2-b532-4748-bfce-1f23be839dc3" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-purple"><code><strong>x_j </strong></code></mark>are the inputs to the neuron.</li></ul><ul id="335ae58f-d5da-4b95-aea7-69b05599d41c" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-purple"><code><strong>wij</strong></code></mark>   are the weights for each input <mark class="highlight-purple"><code><strong>j</strong></code></mark> to neuron <mark class="highlight-purple"><code><strong>i</strong></code></mark>.</li></ul><ul id="3fbb2c06-4e7b-424f-8d9f-95ef387affaa" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-purple"><code><strong>b_i</strong></code></mark> is the bias term for neuron <mark class="highlight-purple"><code><strong>i</strong></code></mark>.</li></ul><ul id="517b22e8-a5dd-468a-9155-b348998cd17a" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-purple"><code><strong>f</strong></code></mark> is an activation function applied to the weighted sum of the inputs plus the bias.</li></ul><p id="85b0db56-2bb0-4d3d-8d78-890b5427c6b2" class=""><mark class="highlight-teal"><code><strong>Dropout</strong></code></mark>: Typically refers to the general dropout applied to the outputs of layers in a neural network, such as the outputs of fully connected layers in an MLP block. It is applied during training to improve generalization. Itâ€™s different from attn_droput which just focusses on dropping the attention scores. Dropout is used to prevent overfitting during training.</p><h3 id="2d3cf39d-006b-46e3-828c-32501287a04d" class="">self.mlp</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22b658e2-36cb-4f72-87a7-0d1093fe5755" class="code"><code class="language-Python">self.mlp = nn.Sequential(
nn.Linear(in_features=embedding_dim, out_features=mlp_size),

nn.GELU(), # &quot;The MLP contains two layers with a GELU non-linearity (section 3.1).&quot;

nn.Dropout(p=dropout),

nn.Linear(in_features=mlp_size, # needs to take same in_features as out_features of layer above
out_features=embedding_dim), # take back to embedding_dim

nn.Dropout(p=dropout) # &quot;Dropout, when used, is applied after every dense layer..&quot;
)</code></pre><p id="f42851cd-23e8-428d-a8ff-881094df161a" class="">
</p><p id="3e25ac1d-09c2-45e9-a1c7-0bd9b017e7bb" class=""><mark class="highlight-blue"><code><strong>self.mlp</strong></code></mark><mark class="highlight-blue"><strong> </strong></mark>is a sequence of layers forming the multi layer perceptron </p><p id="a076bc65-caad-479f-a884-1ed3feb7aee1" class=""><mark class="highlight-blue"><code><strong>nn.Sequential</strong></code></mark>  This is a contianer that allows us to define a sequence of layers that will be applied to input data in a specific order</p><p id="167d3a51-988a-4c9f-ae0e-b8c804461096" class=""><mark class="highlight-blue"><code><strong>nn.Linear</strong></code></mark><strong>:</strong></p><ul id="33da9b8f-b8cd-424a-8cc6-4c1687a23971" class="bulleted-list"><li style="list-style-type:disc"><strong>First Linear Layer:</strong><ul id="5b1b2283-7071-429d-b5d0-afa20979e9c7" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>nn.Linear(in_features=embedding_dim, out_features=mlp_size)</strong></code></mark>: This is a fully connected (dense) layer. It takes the input data with <mark class="highlight-teal"><code><strong>embedding_dim</strong></code></mark> features and transforms it into <mark class="highlight-teal"><code><strong>mlp_size</strong></code></mark> features. Think of this layer as a transformation that changes the data&#x27;s &quot;shape&quot; from one form to another.</li></ul></li></ul><ul id="35c3bb1c-b51b-40ab-9a5c-3174c61d812c" class="bulleted-list"><li style="list-style-type:disc"><strong>Second Linear Layer :</strong><ul id="0414c578-bcfa-4bbe-a529-db64ca35e927" class="bulleted-list"><li style="list-style-type:circle"><mark class="highlight-blue"><code><strong>nn.Linear(in_features=mlp_size, out_features=embedding_dim)</strong></code></mark>: This layer does the reverse transformation. It takes the data with <mark class="highlight-teal"><code><strong>mlp_size</strong></code></mark> features and transforms it back to <mark class="highlight-teal"><code><strong>embedding_dim</strong></code></mark> features. This helps in maintaining the consistency of the data shape across the network.</li></ul></li></ul><p id="e0006472-8704-48c0-a9a4-0dc4997caaf2" class=""><mark class="highlight-blue"><code><strong>nn.GELU:</strong></code></mark></p><ul id="66ed1235-2986-45b5-872c-8ff7853088e2" class="bulleted-list"><li style="list-style-type:disc">The GELU (Gaussian Error Linear Unit) activation function introduces non-linearity into the model, which is crucial for the network to learn complex patterns. Without non-linearity, the network would behave like a simple linear regression, unable to capture intricate relationships in the data.</li></ul><ul id="f2102659-dc68-4175-ac57-91580926dd43" class="bulleted-list"><li style="list-style-type:disc">In simpler terms, GELU decides how much of each neuron&#x27;s output should be passed forward, allowing the network to focus on important features and ignore less important ones.</li></ul><ul id="df40840e-854f-4a11-84fb-e1e344495e16" class="bulleted-list"><li style="list-style-type:disc">Which means it <mark class="highlight-purple"><code><strong>sets all negative values to zero and leaves positive values unchanged.</strong></code></mark></li></ul><h3 id="33dd4ecf-3411-4c07-8bd8-acf05f415496" class="">Why do I need MLP ?</h3><p id="7e57654a-729d-4fd6-8b66-0ee63892535b" class="">Itâ€™s essential for transforming the data and adding non linearity, enabling the model to learn more complex patterns</p><h1 id="cc7fbb17-7cf7-4ce2-af1a-d43b39bc9e35" class="">Transformer Encoder Block </h1><hr id="0d4dbcc6-7e03-4208-8573-9c1377ef5fd1"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="a6abc0b2-d195-48fe-8999-8b3288d63618" class="code"><code class="language-Python"># 1. Create a class that inherits from nn.Module
class TransformerEncoderBlock(nn.Module):
    &quot;&quot;&quot;Creates a Transformer Encoder block.&quot;&quot;&quot;
    # 2. Initialize the class with hyperparameters from Table 1 and Table 3
    def __init__(self,
                 embedding_dim:int=768, # Hidden size D from Table 1 for ViT-Base
                 num_heads:int=12, # Heads from Table 1 for ViT-Base
                 mlp_size:int=3072, # MLP size from Table 1 for ViT-Base
                 mlp_dropout:float=0.1, # Amount of dropout for dense layers from Table 3 for ViT-Base
                 attn_dropout:float=0): # Amount of dropout for attention layers
        super().__init__()

        # 3. Create MSA block (equation 2)
        self.msa_block = MultiheadSelfAttentionBlock(embedding_dim=embedding_dim,
                                                     num_heads=num_heads,
                                                     attn_dropout=attn_dropout)

        # 4. Create MLP block (equation 3)
        self.mlp_block =  MLPBlock(embedding_dim=embedding_dim,
                                   mlp_size=mlp_size,
                                   dropout=mlp_dropout)

    # 5. Create a forward() method
    def forward(self, x):

        # 6. Create residual connection for MSA block (add the input to the output)
        x =  self.msa_block(x) + x

        # 7. Create residual connection for MLP block (add the input to the output)
        x = self.mlp_block(x) + x

        return x</code></pre><p id="1a002cc4-d668-4e57-abf0-c9bb0c3a4cb1" class=""><br/>The <br/><mark class="highlight-blue"><code><strong>TransformerEncoderBlock</strong></code></mark> class is responsible for creating a single encoder block of the transformer architecture. This block consists of an MSA block followed by an MLP block, each of which has a residual connection around it. The forward method processes the input data through these components.<br/><br/></p><p id="08e1d517-9250-4da3-a925-dd50cbc63f8c" class="">It has MSA block and MLP block discussed above and along with that</p><p id="dba85bf8-81ff-4054-baf7-66f636614eca" class="">the method <mark class="highlight-blue"><code><strong>forward</strong></code></mark> </p><p id="538066a6-6614-4f94-8f98-558e86be066a" class="">The input to the forward method is a tensor <mark class="highlight-blue"><code><strong>x</strong></code></mark>, which represents the input data</p><p id="c7dba757-164b-429e-88e6-ca3e4e1051d1" class="">This method defines how the input data passes through the transformer encoder block.</p><blockquote id="2684cd7f-59c7-42eb-8d89-696c97a5bb9a" class="">The input <mark class="highlight-blue"><code><strong>x</strong></code></mark> is passed through the MSA block. The output of the MSA block is then added to the original input <mark class="highlight-blue"><code><strong>x</strong></code></mark> to form a residual connection.</blockquote><blockquote id="ae07da92-b082-4f85-a7dc-f86214f1c55f" class="">The output from the previous step is passed through the MLP block. The output of the MLP block is then added to the input of this block to form another residual connection.</blockquote><p id="48dd09ee-a625-4778-bda0-c1a23ce74c3c" class="">and <mark class="highlight-blue"><code><strong>x</strong></code></mark><mark class="highlight-blue"><strong> </strong></mark>is<mark class="highlight-blue"> </mark> returned</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="b4ea1ba5-077e-486a-8665-9635f625a416"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%"><mark class="highlight-red"><strong>Residual connections </strong></mark>are also called as skip connections, which are architectural features used in deep learning Residual connections involve adding the input of a layer to its output.                                                                                                                                                                                             This means the layer only needs to learn the difference (or &quot;residual&quot;) between the input and the output, rather than learning the entire transformation from scratch.</div></figure><p id="39ebcd6a-7c00-4e98-83f5-8bc6391f85e2" class="">It adds the inputs of the layers to the input vectors to preserve the input features and the newly learnt features are present in the final output</p><hr id="60b9a1a5-e542-44fd-b10e-677659620756"/><h1 id="64633629-a875-46ba-86dc-c6b1a62108dd" class="">VIT class  -  the transformer classs ðŸ’€</h1><hr id="e4b81e86-ccd6-4562-bf33-3bcf98326fd0"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="821c63a6-9294-4ca7-8c21-1945178a7191" class="code"><code class="language-Python"># 1. Create a ViT class that inherits from nn.Module
class ViT(nn.Module):
    &quot;&quot;&quot;Creates a Vision Transformer architecture with ViT-Base hyperparameters by default.&quot;&quot;&quot;
    # 2. Initialize the class with hyperparameters from Table 1 and Table 3
    def __init__(self,
                 img_size:int=224, # Training resolution from Table 3 in ViT paper
                 in_channels:int=1, # Number of channels in input image
                 patch_size:int=16, # Patch size
                 num_transformer_layers:int=12, # Layers from Table 1 for ViT-Base
                 embedding_dim:int=768, # Hidden size D from Table 1 for ViT-Base
                 mlp_size:int=3072, # MLP size from Table 1 for ViT-Base
                 num_heads:int=12, # Heads from Table 1 for ViT-Base
                 attn_dropout:float=0, # Dropout for attention projection
                 mlp_dropout:float=0.1, # Dropout for dense/MLP layers
                 embedding_dropout:float=0.1, # Dropout for patch and position embeddings
                 num_classes:int=1000): # Default for ImageNet but can customize this
        super().__init__() # don&#x27;t forget the super().__init__()!

        # 3. Make the image size is divisble by the patch size
        assert img_size % patch_size == 0, f&quot;Image size must be divisible by patch size, image size: {img_size}, patch size: {patch_size}.&quot;

        # 4. Calculate number of patches (height * width/patch^2)
        self.num_patches = (img_size * img_size) // patch_size**2

        # 5. Create learnable class embedding (needs to go at front of sequence of patch embeddings)
        self.class_embedding = nn.Parameter(data=torch.randn(1, 1, embedding_dim),
                                            requires_grad=True)

        # 6. Create learnable position embedding
        self.position_embedding = nn.Parameter(data=torch.randn(1, self.num_patches+1, embedding_dim),
                                               requires_grad=True)

        # 7. Create embedding dropout value
        self.embedding_dropout = nn.Dropout(p=embedding_dropout)

        # 8. Create patch embedding layer
        self.patch_embedding = PatchEmbedding(in_channels=in_channels,
                                              patch_size=patch_size,
                                              embedding_dim=embedding_dim)

        # 9. Create Transformer Encoder blocks (we can stack Transformer Encoder blocks using nn.Sequential())
        # Note: The &quot;*&quot; means &quot;all&quot;
        self.transformer_encoder = nn.Sequential(*[TransformerEncoderBlock(embedding_dim=embedding_dim,
                                                                            num_heads=num_heads,
                                                                            mlp_size=mlp_size,
                                                                            mlp_dropout=mlp_dropout) for _ in range(num_transformer_layers)])

        # 10. Create classifier head
        self.classifier = nn.Sequential(
            nn.LayerNorm(normalized_shape=embedding_dim),
            nn.Linear(in_features=embedding_dim,
                      out_features=num_classes)
        )

    # 11. Create a forward() method
    def forward(self, x):

        # 12. Get batch size
        batch_size = x.shape[0]

        # 13. Create class token embedding and expand it to match the batch size (equation 1)
        class_token = self.class_embedding.expand(batch_size, -1, -1) # &quot;-1&quot; means to infer the dimension (try this line on its own)

        # 14. Create patch embedding (equation 1)
        x = self.patch_embedding(x)

        # 15. Concat class embedding and patch embedding (equation 1)
        x = torch.cat((class_token, x), dim=1)

        # 16. Add position embedding to patch embedding (equation 1)
        x = self.position_embedding + x

        # 17. Run embedding dropout (Appendix B.1)
        x = self.embedding_dropout(x)

        # 18. Pass patch, position and class embedding through transformer encoder layers (equations 2 &amp; 3)
        x = self.transformer_encoder(x)

        # 19. Put 0 index logit through classifier (equation 4)
        x = self.classifier(x[:, 0]) # run on each sample in a batch at 0 index

        return x</code></pre><ul id="c8b3d8b2-8789-42f9-9ecd-59c1ddee7d3f" class="bulleted-list"><li style="list-style-type:disc"><strong>img_size:</strong> Size of the input images (assumed to be square).</li></ul><ul id="54ca2c10-2ec0-444d-99cf-6c59f8818018" class="bulleted-list"><li style="list-style-type:disc"><strong>in_channels:</strong> Number of channels in the input images (1 for grayscale, 3 for RGB).</li></ul><ul id="a7997c27-ba07-4ceb-aa83-63e5498f54fa" class="bulleted-list"><li style="list-style-type:disc"><strong>patch_size:</strong> Size of the patches the image is divided into.</li></ul><ul id="03ddd63c-f923-41c4-8eea-685a1a550c4f" class="bulleted-list"><li style="list-style-type:disc"><strong>num_transformer_layers:</strong> Number of Transformer Encoder layers.</li></ul><ul id="fda1dff1-dced-4d93-b088-9592d13d9662" class="bulleted-list"><li style="list-style-type:disc"><strong>embedding_dim:</strong> Dimensionality of the embedding space.</li></ul><ul id="3261e361-12a4-422e-9709-60a7e974197c" class="bulleted-list"><li style="list-style-type:disc"><strong>mlp_size:</strong> Size of the hidden layer in the MLP block.</li></ul><ul id="741a56b8-0b74-4ddf-a7f5-6a511a7bd658" class="bulleted-list"><li style="list-style-type:disc"><strong>num_heads:</strong> Number of attention heads in the MultiheadSelfAttentionBlock.</li></ul><ul id="d7db052d-2f63-4cb0-be11-da37b47f86b9" class="bulleted-list"><li style="list-style-type:disc"><strong>attn_dropout:</strong> Dropout rate for the attention mechanism.</li></ul><ul id="b6577fa1-e9c3-4f9c-a701-777c2b289078" class="bulleted-list"><li style="list-style-type:disc"><strong>mlp_dropout:</strong> Dropout rate for the MLP layers.</li></ul><ul id="78d5f902-9811-450a-9e7c-eae559badd1a" class="bulleted-list"><li style="list-style-type:disc"><strong>embedding_dropout:</strong> Dropout rate for the embedding layers.</li></ul><ul id="49c3b13f-539f-4fb2-83d6-1d2706c332c8" class="bulleted-list"><li style="list-style-type:disc"><strong>num_classes:</strong> Number of output classes for classification.</li></ul><hr id="95b69c8a-790f-44cf-bf6e-614eb288f7ca"/><h3 id="ff19b05c-2e2d-464b-8e18-4043cdf0fbc2" class="">self.transformer_encoder</h3><p id="3fb5dd6b-4c72-4592-bbb9-922266518f4e" class="">itâ€™s a stack of multiple <mark class="highlight-blue"><code><strong>TransformerEncoderBlock</strong></code></mark> instances which process the input patch embeddings through multiple layers of attention and feed forward operatoins</p><p id="d5205237-4cf7-45ba-9a83-6ffbd1cc2adf" class="">The instances are stacked using <mark class="highlight-blue"><code><strong>nn.Sequential</strong></code></mark><mark class="highlight-blue"><strong>  </strong></mark>and created using normal list comprehension</p><ul id="668d6e05-f47e-46f6-a00c-4d7088513b55" class="bulleted-list"><li style="list-style-type:disc">the * operator is for unpacking the list and separate the arguments for  <mark class="highlight-blue"><code><strong>nn.Sequential</strong></code></mark><mark class="highlight-blue"><strong> </strong></mark></li></ul><hr id="293043b0-e302-450b-bd2c-84ba573b3c7f"/><h3 id="ea4e3ad0-82f5-43d6-ad3d-6c5541e5af01" class="">self.forward() in VIT class</h3><ul id="153ae73a-a84e-4c21-9f13-99f488c8c9e5" class="bulleted-list"><li style="list-style-type:disc">First we get the batch size using the slicing  <mark class="highlight-blue"><code><strong>x.shape[0]</strong></code></mark></li></ul><ul id="954e8aab-7a13-4702-8fae-282f3d0d4588" class="bulleted-list"><li style="list-style-type:disc">And then we create a class token with the snippet </li></ul><ul id="a688f949-320c-4ee8-8836-9ddb8c7ad5e8" class="toggle"><li><details open=""><summary><mark class="highlight-blue"><code><strong>class_token = self.class_embedding.expand(batch_size, -1, -1)</strong></code></mark></summary><ul id="1f3f08e9-b96a-4752-aa9c-cb82dd57de5b" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>self.class_embedding</strong></code></mark> is a learnable parameter initialized as a tensor with shape <mark class="highlight-red"><code><strong>[1,1,embedding_dim]</strong></code></mark><mark class="highlight-red"><strong>  </strong></mark>it represents a class_token</li></ul><ul id="d92474ea-c22e-4d1e-a9b2-7ab434a8c4a9" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-blue"><code><strong>.expand()</strong></code></mark><mark class="highlight-blue"><strong>  </strong></mark>in this context specifies to expand the class_token to match the batch size coz initially when itâ€™s created, itâ€™s batch_size is specified to be 1</li></ul><ul id="005fa9a9-ae70-4a4d-bf28-4174f89a3ca0" class="bulleted-list"><li style="list-style-type:disc"> -1 : the second and third parameters say that they are not changed, they remain as the original tensor</li></ul><ul id="4349bf3a-2a7f-4108-9a6a-066415a295d4" class="bulleted-list"><li style="list-style-type:disc">expansion changes the shape of the class token from <code><strong>[1,1,embedding_dim]</strong></code>  to <code><strong>[batch_size,1,embedding_dim]</strong></code></li></ul><p id="b2a9f6e2-ce63-4a28-82b0-a1721897325b" class="">
</p></details></li></ul><ul id="bb242311-a0ef-4257-8267-5b0f5eeb9617" class="bulleted-list"><li style="list-style-type:disc">Then the input image tensor undergoes patch_embedding</li></ul><ul id="0b3bd9f2-c0e2-4e65-91c4-d2f7c4663f9b" class="bulleted-list"><li style="list-style-type:disc">Then the class tokenâ€™s are added to the patch_embeddings</li></ul><ul id="e33b9904-36e1-4305-ad34-8c21efc4cbd4" class="bulleted-list"><li style="list-style-type:disc">Further, we create position_embeddings and add them to patch_embeddings</li></ul><ul id="8f7b98a0-7664-42ef-a1a8-c02e20b868b3" class="bulleted-list"><li style="list-style-type:disc">Then we apply the embedding dropout to the processed embeddings</li></ul><ul id="ee535704-0d2a-4e6a-b68f-bde190211635" class="bulleted-list"><li style="list-style-type:disc">And then we pass it through encoder layers and finally</li></ul><ul id="d29ffb2e-30f9-431e-b1f9-ee655a665fde" class="toggle"><li><details open=""><summary><mark class="highlight-blue"><code><strong>self.classifier</strong></code></mark><mark class="highlight-blue"><strong> </strong></mark>which predicts</summary><ul id="0635cfe1-2ea5-4444-9a8b-86b4d6b0f353" class="bulleted-list"><li style="list-style-type:disc">Itâ€™s the final part of the network producing the final output i.e. the predictions</li></ul><ul id="049530fd-55f3-4664-ad78-190926334a1a" class="bulleted-list"><li style="list-style-type:disc">it has a normalization layer and a Linear layer</li></ul><ul id="96076ae5-d2d7-4dcd-b9df-7d9a649a83a3" class="bulleted-list"><li style="list-style-type:disc">The layer norm is applied to normalize the last layer of the encoder so that the input layer next recieves a stable distribution</li></ul><ul id="32241ae8-5d01-48e9-8f8e-ce57e331e759" class="bulleted-list"><li style="list-style-type:disc">and then the Linear layer is used to map the normalized embeddings to the output layer</li></ul><ul id="71269f54-e709-4535-8c14-4de115befa1a" class="bulleted-list"><li style="list-style-type:disc">it performs a linear transformation to the input data : <mark class="highlight-teal"><code><strong>output = input * weights + bias</strong></code></mark>  the weights and biases are learnable and updated during training</li></ul><blockquote id="bd87b38e-52ce-44cb-9b75-26917482f4d6" class="">In The classifier, till then we have a batch of 32 images which have 197 tokens with 768 embeddings each. Now we just take the class_token token at the beginning and then ignore the next 196 patches (or) tokens and then use the class_token which is of shape       ( batch_size * embedding_dim )  and then send that to classifier, which transforms the 768 embeddings to 3 outputs in the final layer. From there the output is determined</blockquote><p id="87ab2c7d-0f97-4018-ad3d-642c552bddde" class="">
</p></details></li></ul><hr id="1a29364c-f92c-4bc6-b3db-02bd6f74b970"/><h1 id="260b8c08-7b5b-405d-b442-7241798babaa" class="">Final cell  â€” the training</h1><hr id="0c4f72df-c98a-4118-80b9-d4367929c51f"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="aa85226c-2755-4a83-b9e3-5e636cad67e2" class="code"><code class="language-Python">
# Setup the optimizer to optimize our ViT model parameters using hyperparameters from the ViT paper
optimizer = torch.optim.Adam(params=vit.parameters(),
                             lr=3e-3, # Base LR from Table 3 for ViT-* ImageNet-1k
                             betas=(0.9, 0.999), # default values but also mentioned in ViT paper section 4.1 (Training &amp; Fine-tuning)
                             weight_decay=0.3) # from the ViT paper section 4.1 (Training &amp; Fine-tuning) and Table 3 for ViT-* ImageNet-1k

# Setup the loss function for multi-class classification
loss_fn = torch.nn.CrossEntropyLoss()

# Set the seeds
set_seeds()

# Train the model and save the training results to a dictionary
results = train(model=vit,
                       train_dataloader=train_dataloader,
                       test_dataloader=test_dataloader,
                       optimizer=optimizer,
                       loss_fn=loss_fn, 
                       epochs=10,
                       device=device)</code></pre><p id="bf6b3c84-9f39-4d2b-92d8-eaab34995957" class=""><mark class="highlight-teal"><code><strong>Optimizer</strong></code></mark> : An optimizer is an algorithm that adjusts the parameters of a model during training to minimize the error or loss function. It does this by updating the model&#x27;s parameters based on the gradients of the loss function with respect to those parameters.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="ee7e82e6-2e47-4536-94ba-dac42144bc87"><div style="font-size:1.5em"><span class="icon">ðŸ’¡</span></div><div style="width:100%">Parameters in an optimizer<br/><br/><mark class="highlight-blue"><code><strong><span style="border-bottom:0.05em solid">params</span></strong></code></mark>:  Here the model parameters are specified that will be optimized<br/>it will take <br/><mark class="highlight-blue"><code><strong>vit.parameters()</strong></code></mark>  which gives an iterable with all the trainable parameters<br/><br/><mark class="highlight-blue"><code><strong><span style="border-bottom:0.05em solid">lr</span></strong></code></mark>: it controls the rate of steps taken during the optimization itâ€™s the (learning rate).         It determines the rate at which the optimizer adjusts the model parameters in the direction that minimizes the loss.</div></figure><ul id="ea5a6117-c96a-4ac5-9c08-7fa242f46537" class="toggle"><li><details open=""><summary><mark class="highlight-purple"><code><strong><span style="border-bottom:0.05em solid">optional</span></strong></code></mark></summary><ul id="6d46d346-667a-4f9f-bbc7-af2a62ca6a60" class="bulleted-list"><li style="list-style-type:disc"><strong>betas (optional, default=(0.9, 0.999)):</strong><ul id="54091ce2-76d9-4174-bb56-8eb3e0e205e0" class="bulleted-list"><li style="list-style-type:circle">Beta parameters are used in the Adam optimizer to compute exponentially weighted averages of gradients and squared gradients.</li></ul><ul id="5026cbdf-1080-4cc6-856a-b9bfe5f48f8a" class="bulleted-list"><li style="list-style-type:circle">The first beta parameter (beta1) controls the exponential decay rate for the first moment (mean) of gradients.</li></ul><ul id="976cac64-9b86-4101-9cba-1fefe3bad851" class="bulleted-list"><li style="list-style-type:circle">The second beta parameter (beta2) controls the exponential decay rate for the second moment (uncentered variance) of gradients.</li></ul></li></ul><ul id="9a166a7e-9e49-4e4d-bde4-5929867fe405" class="bulleted-list"><li style="list-style-type:disc"><strong>weight_decay (optional, default=0):</strong><ul id="7f3c0d3f-9db8-49cd-8994-5b81a17ea64d" class="bulleted-list"><li style="list-style-type:circle">Weight decay (also known as L2 regularization) adds a penalty term to the loss function proportional to the square of the magnitude of the model&#x27;s parameters.</li></ul><ul id="37b2d7eb-cbe7-4633-9781-19998cdc5233" class="bulleted-list"><li style="list-style-type:circle">It encourages the model to learn simpler patterns by penalizing large parameter values, thereby helping prevent overfitting.</li></ul></li></ul></details></li></ul><p id="30cd1541-d585-41f7-b409-07bbe45437d4" class=""><mark class="highlight-teal"><code><strong>Loss Function</strong></code></mark> : A loss function quantifies the difference between the predicted outputs of a model and the true labels or targets in the training data. The choice of loss function depends on the type of task being performed. For classification tasks like image classification, CrossEntropyLoss is commonly used. CrossEntropyLoss measures the difference between the predicted probability distribution and the true probability distribution of the classes. It scolds model when it makes large errors ans less scoldings when it performs better</p><figure id="a70deacd-302b-4345-9605-aaa59fcfde59" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>CategoricalÂ Cross-EntropyÂ Loss</mtext><mo>=</mo><mo>âˆ’</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>âˆ‘</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>y</mi><mrow><mtext>true</mtext><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>â‹…</mo><mi>log</mi><mo>â¡</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mtext>pred</mtext><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Categorical Cross-Entropy Loss} = -\frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{C} y_{\text{true},i,j} \cdot \log(y_{\text{pred},i,j})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">CategoricalÂ Cross-EntropyÂ Loss</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.2421em;vertical-align:-1.4138em;"></span><span class="mord">âˆ’</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">âˆ‘</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">true</span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">â‹…</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">pred</span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></div></figure><ul id="d15c5668-9bf3-4d86-94fd-4f79f2ac9e66" class="bulleted-list"><li style="list-style-type:disc">n is the number of samples</li></ul><ul id="27f04638-ec7a-47a1-a837-a7ca33a621a7" class="bulleted-list"><li style="list-style-type:disc">C is the number of classes</li></ul><ul id="f5f0c29d-a2f1-412a-9e71-57e268437e18" class="bulleted-list"><li style="list-style-type:disc">Y_true_i_j denotes the true label of sample i for class j</li></ul><ul id="001f7807-f673-4436-a3bb-962e76f18646" class="bulleted-list"><li style="list-style-type:disc">Y_pred_i_j denotes the predicted probability of sample i for class j</li></ul><hr id="800c2a26-74dd-4d4a-af89-77ed01bcd55a"/><h3 id="04586939-6a82-49aa-856b-7136a0eaa81e" class="">Training Process</h3><ol type="1" id="bb422f6b-8852-498d-b17c-2e4ea7a6a109" class="numbered-list" start="1"><li><strong>Initialization</strong>:<ul id="a0a1cd27-1016-4879-895f-fd33e0f49e94" class="bulleted-list"><li style="list-style-type:disc"><strong>Weights and Biases</strong>: The model&#x27;s weights (parameters) are initialized, typically with small random values. These weights are associated with different parts of the network (e.g., in the attention heads and feed-forward layers).</li></ul><ul id="07ecfe11-e41e-4148-ad91-fd778b67ddb2" class="bulleted-list"><li style="list-style-type:disc"><strong>Positional Encodings</strong>: If positional encodings are learnable (as in some implementations), they are also initialized.</li></ul></li></ol><ol type="1" id="ef7b7154-e495-4f87-a766-bbd0be798502" class="numbered-list" start="2"><li><strong>Forward Pass</strong>:<ul id="e7895f02-8690-4af3-b266-8f221e00c4bf" class="bulleted-list"><li style="list-style-type:disc"><strong>Input Data</strong>: The model takes in a batch of input data (e.g., images for ViTs).</li></ul><ul id="62a69267-95ac-4126-8478-8bf437d41c09" class="bulleted-list"><li style="list-style-type:disc"><strong>Patching and Embedding</strong>: Each input image is divided into patches, which are then flattened and linearly projected into the embedding space.</li></ul><ul id="ba4bc3cc-0171-4478-9120-e2a2beb0650b" class="bulleted-list"><li style="list-style-type:disc"><strong>Adding Positional Encodings</strong>: Positional encodings are added to the patch embeddings to incorporate spatial information.</li></ul><ul id="79a323ab-3bc9-4551-9baa-19ac2449f6de" class="bulleted-list"><li style="list-style-type:disc"><strong>Attention Mechanism</strong>: Each patch&#x27;s embedding is processed through multiple layers of self-attention and feed-forward networks. This involves calculating the attention scores and combining information from different patches.</li></ul><ul id="53f50681-7ff5-4ac0-9ee5-964cc2aef6d1" class="bulleted-list"><li style="list-style-type:disc"><strong>Output</strong>: The model produces an output, typically logits or probabilities for classification tasks.</li></ul></li></ol><ol type="1" id="e0474fed-da20-44ac-aa47-54544950e737" class="numbered-list" start="3"><li><strong>Loss Computation</strong>:<ul id="b87242c3-6144-4554-ac69-ca312ae4997c" class="bulleted-list"><li style="list-style-type:disc">The model&#x27;s output is compared to the ground truth labels using a loss function (e.g., cross-entropy loss for classification).</li></ul><ul id="3d37755a-dbc6-40ee-bf25-eda6f129afa2" class="bulleted-list"><li style="list-style-type:disc">The loss function quantifies the difference between the model&#x27;s predictions and the actual labels.</li></ul></li></ol><ol type="1" id="497aecd9-d4a8-4a90-8d98-a390ac6b87cb" class="numbered-list" start="4"><li><strong>Backward Pass (Backpropagation)</strong>:<ul id="6613362f-5600-42c1-a9c3-617d30ec7ec1" class="bulleted-list"><li style="list-style-type:disc"><strong>Gradient Calculation</strong>: Gradients of the loss with respect to each model parameter are computed. This is done using the chain rule of calculus through automatic differentiation.</li></ul><ul id="aec8f51c-7088-4bbf-b2e3-45acec1d2738" class="bulleted-list"><li style="list-style-type:disc"><strong>Gradient Flow</strong>: Gradients are propagated backward through the network, updating weights from the output layer to the input layer.</li></ul></li></ol><ol type="1" id="ac7c4b2e-f837-4d8d-8611-3c6514f282ec" class="numbered-list" start="5"><li><strong>Parameter Update</strong>:<ul id="0c047c72-1710-4eec-b39c-ba0a67fc6a91" class="bulleted-list"><li style="list-style-type:disc"><strong>Optimization</strong>: An optimizer (e.g., Adam or SGD) updates the model&#x27;s parameters using the gradients. The update is typically done using a learning rate that determines the step size of the update.</li></ul><ul id="6ba768f3-5834-477f-a726-2f93e362b5f2" class="bulleted-list"><li style="list-style-type:disc"><strong>Weight Adjustment</strong>: Weights and biases are adjusted to minimize the loss function, moving the model closer to making accurate predictions.</li></ul></li></ol><ol type="1" id="a0f3d3e3-a304-4f83-924b-d9075f5989f1" class="numbered-list" start="6"><li><strong>Iteration</strong>:<ul id="36897f5b-bd3a-40e0-9dc6-9dc73bdb3793" class="bulleted-list"><li style="list-style-type:disc">The above steps are repeated for multiple iterations (epochs) over the training data.</li></ul><ul id="1922284e-21d7-4155-bc09-856919562102" class="bulleted-list"><li style="list-style-type:disc">During each epoch, the entire training dataset is passed through the model once, and weights are updated.</li></ul></li></ol><ol type="1" id="12458c81-a2d4-463e-acd3-4ffe4e09a8da" class="numbered-list" start="7"><li><strong>Evaluation</strong>:<ul id="0cfe17ae-c522-40db-ac67-35254f6da49b" class="bulleted-list"><li style="list-style-type:disc">After each epoch or periodically during training, the model&#x27;s performance is evaluated on a separate validation set.</li></ul><ul id="6ff2b9b6-414a-4143-9309-ccb2ed804f7d" class="bulleted-list"><li style="list-style-type:disc">Metrics such as accuracy, precision, recall, or F1 score are calculated to monitor the modelâ€™s progress.</li></ul></li></ol><ol type="1" id="852a72a2-02e7-4b1a-b10e-2a58b3857728" class="numbered-list" start="8"><li><strong>Stopping Criteria</strong>:<ul id="07d7c616-c2e8-45ad-9024-945eb0707de4" class="bulleted-list"><li style="list-style-type:disc">Training continues until a predefined stopping criterion is met, such as a fixed number of epochs, convergence of the loss, or early stopping based on validation performance.</li></ul></li></ol><h3 id="80f48484-a97a-4dfe-bfc0-b747283182e9" class="">Detailed Steps in a Vision Transformer (ViT) Training</h3><p id="114a1bed-5614-45df-9b8c-2d9429869076" class="">In the context of a Vision Transformer, the training involves the following specific operations:</p><ol type="1" id="1e45176e-a42b-43e4-93ef-355f9fced4f8" class="numbered-list" start="1"><li><strong>Patching and Embedding</strong>:<ul id="4b3467d3-8ee9-4317-bf31-5469535ecc5c" class="bulleted-list"><li style="list-style-type:disc">Input image X of size HÃ—WÃ—C is split into patches Pi of size PÃ—P.<p id="4f7061aa-c9fc-4c7b-bd24-b1cb9b28dbc8" class="">X\mathbf{X}</p><p id="1de4c5f6-e142-43c7-accb-7cc8cfe1959f" class="">HÃ—WÃ—CH \times W \times C</p><p id="d3418723-c7b4-400b-ba72-0d46972e9cc0" class="">Pi\mathbf{P}_i</p><p id="2fd45092-614a-490c-bd91-0794b8d6bdb1" class="">PÃ—PP \times P</p></li></ul><ul id="cac395e3-938c-4fcd-86c2-5a19f4402a9f" class="bulleted-list"><li style="list-style-type:disc">Each patch Pi is flattened into a vector pi and projected into an embedding space using a linear layer, resulting in patch embeddings Ei.<p id="1ee830ba-c8d9-4242-bb99-80bd43b10dbb" class="">Pi\mathbf{P}_i</p><p id="1cdefebd-24a0-431c-af69-1fa3581331d8" class="">pi\mathbf{p}_i</p><p id="9e98a1e2-0030-4180-b44c-16150892616a" class="">Ei\mathbf{E}_i</p></li></ul></li></ol><ol type="1" id="6ec1330b-739f-43fd-ba9d-22ea28259244" class="numbered-list" start="2"><li><strong>Adding the [CLS] Token</strong>:<ul id="20179476-5bc2-4440-91ee-c236be1507f6" class="bulleted-list"><li style="list-style-type:disc">A special [CLS] token is prepended to the sequence of patch embeddings.</li></ul><ul id="0c54115d-8325-45fb-8066-551412ed810f" class="bulleted-list"><li style="list-style-type:disc">The [CLS] token is used to aggregate information from all patches and typically represents the whole image.</li></ul></li></ol><ol type="1" id="58890b56-57a6-4a7b-9bfa-462d4ddc9f3e" class="numbered-list" start="3"><li><strong>Adding Positional Encodings</strong>:<ul id="466b2f92-197e-440a-9cab-754315019b2b" class="bulleted-list"><li style="list-style-type:disc">Positional encodings are added to the patch embeddings to retain spatial information.</li></ul><ul id="78ebd3d6-b3bd-4694-ac84-8bbc090ad478" class="bulleted-list"><li style="list-style-type:disc">These encodings can be fixed or learnable and help the model understand the position of each patch in the original image.</li></ul></li></ol><ol type="1" id="117a2447-901e-402b-8fea-10eca3ca0aa2" class="numbered-list" start="4"><li><strong>Multi-Head Self-Attention</strong>:<ul id="29f6aafd-17e4-43d2-93e3-7c281871ae4e" class="bulleted-list"><li style="list-style-type:disc">For each layer in the transformer, the model computes self-attention scores for each patch relative to every other patch.</li></ul><ul id="860e1d8e-b4c6-44f4-b925-41d833af10d1" class="bulleted-list"><li style="list-style-type:disc">This allows the model to focus on different parts of the image and learn contextual relationships between patches.</li></ul></li></ol><ol type="1" id="45efe247-8390-4098-9a0b-45f41fd0f32b" class="numbered-list" start="5"><li><strong>Feed-Forward Neural Networks</strong>:<ul id="5e989e48-a3aa-4af4-8cde-8b5d288c01c3" class="bulleted-list"><li style="list-style-type:disc">Each attention output is passed through a feed-forward network to apply further transformations.</li></ul><ul id="f284dbf1-2fe6-4e46-9353-486bad3cddc1" class="bulleted-list"><li style="list-style-type:disc">These networks typically consist of linear layers and activation functions, such as GELU (Gaussian Error Linear Unit).</li></ul></li></ol><ol type="1" id="d66afdae-4aac-4ea8-a620-62137ac9ee55" class="numbered-list" start="6"><li><strong>Layer Normalization</strong>:<ul id="c5bb9cd7-7089-4060-8974-781a1b5c1c3f" class="bulleted-list"><li style="list-style-type:disc">Layer normalization is applied to stabilize and normalize the outputs from the attention and feed-forward layers.</li></ul><ul id="b21b4279-b6c9-4929-a201-0f38e6e4fce4" class="bulleted-list"><li style="list-style-type:disc">It ensures that each layer has a consistent distribution of activations.</li></ul></li></ol><ol type="1" id="f4f693cf-d01d-4a1c-bddd-b6c8c2c6278a" class="numbered-list" start="7"><li><strong>Output Processing</strong>:<ul id="509fb923-dd9c-41b1-bba5-22adcf6dc929" class="bulleted-list"><li style="list-style-type:disc">After passing through several transformer layers, the final [CLS] token output is used for classification.</li></ul><ul id="35b6d008-3ba1-4a47-87d2-0ba62282fac3" class="bulleted-list"><li style="list-style-type:disc">The [CLS] token represents a learned global representation of the input image.</li></ul></li></ol><p id="9adf81f6-8317-498d-aec3-b949ea88d4a3" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>
